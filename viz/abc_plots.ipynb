{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ABC Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "Generates ABC result figures for \n",
    "\n",
    "Adaptive Bias Correction for Improved Subseasonal Forecasting\n",
    "\n",
    "Soukayna Mouatadid, Paulo Orenstein, Genevieve Flaspohler, \n",
    "Judah Cohen, Miruna Oprescu, Ernest Fraenkel, and Lester Mackey. \n",
    "\"\"\"\n",
    "# Ensure notebook is being run from base repository directory\n",
    "import os, sys\n",
    "try:\n",
    "    os.chdir(\"/home/{}/forecast_rodeo_ii/\".format(os.environ[\"USER\"]))\n",
    "except Exception as err:\n",
    "    print(f\"Warning: unable to change directory; {repr(err)}\")\n",
    "    \n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline    \n",
    "    \n",
    "import itertools\n",
    "import importlib\n",
    "import subprocess\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import product\n",
    "from functools import partial\n",
    "from datetime import datetime\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "import copy\n",
    "import pdb\n",
    "import calendar \n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "import matplotlib   \n",
    "from matplotlib.gridspec import GridSpec\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "\n",
    "from subseasonal_toolkit.utils.experiments_util import pandas2hdf\n",
    "from subseasonal_toolkit.utils.general_util import printf\n",
    "from subseasonal_toolkit.utils.eval_util import get_target_dates, score_to_mean_rmse, contest_quarter_start_dates, contest_quarter\n",
    "from subseasonal_toolkit.utils.models_util import get_selected_submodel_name\n",
    "\n",
    "from viz_util_abc import get_metrics_df, plot_metric_maps, get_models_metric_lat_lon, plot_metric_maps, add_groupby_cols, all_model_names\n",
    "\n",
    "\n",
    "# set figure and font sizes for seaborn plots\n",
    "sns.set(rc={'figure.figsize':(8,6)}, font_scale=1)\n",
    "\n",
    "#\n",
    "# Directory for saving output\n",
    "#\n",
    "out_dir = \"/home/{}/forecast_rodeo_ii/subseasonal_toolkit/viz\".format(os.environ[\"USER\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "# Full set of regions, times, and tasks to evaluate\n",
    "#\n",
    "metrics = [\"rmse\", \"skill\", \"score\"]\n",
    "\n",
    "contest_gt_ids = [\"contest_tmp2m\", \"contest_precip\"]\n",
    "us_gt_ids = [\"us_tmp2m\", \"us_precip\"]\n",
    "east_gt_ids = [\"east_tmp2m\", \"east_precip\"]\n",
    "us_1_5_gt_ids = [\"us_tmp2m_1.5x1.5\", \"us_precip_1.5x1.5\"]\n",
    "\n",
    "# All ground truth ids\n",
    "gt_ids = contest_gt_ids + us_gt_ids \n",
    "\n",
    "horizons = [\"12w\", \"34w\", \"56w\"]\n",
    "target_eval_dates = [\"std_paper\", \"std_contest\"]\n",
    "\n",
    "# The full set of models we to evaluate in some\n",
    "# experiment \n",
    "all_models = [\n",
    "    # Raw Baselines\n",
    "    'raw_cfsv2', \n",
    "    # Baselines\n",
    "    \"climatology\",   \n",
    "    'deb_cfsv2',\n",
    "    'persistence',\n",
    "    # ECMWF\n",
    "    'ecmwf'\n",
    "    # Toolkit \n",
    "    'tuned_climpp',\n",
    "    'tuned_cfsv2pp',\n",
    "    'perpp',\n",
    "    #Learning\n",
    "    'autoknn',\n",
    "    'informer',\n",
    "    'tuned_localboosting',\n",
    "    'multillr',\n",
    "    'nbeats',\n",
    "    'prophet',\n",
    "    'salient',\n",
    "    'tuned_salient2',\n",
    "    #Ensembles\n",
    "    'linear_ensemble',  \n",
    "    'online_learning'\n",
    "]\n",
    "\n",
    "# Main experiment model names\n",
    "main_experiment_models = [\n",
    "    # Baselines\n",
    "    \"climatology\",   \n",
    "    'deb_cfsv2',\n",
    "    'persistence',\n",
    "    # Toolkit \n",
    "    'tuned_climpp',\n",
    "    'tuned_cfsv2pp',\n",
    "    'perpp',\n",
    "    #Learning\n",
    "    'autoknn',\n",
    "    'tuned_localboosting',\n",
    "    'multillr',\n",
    "    'nbeats',\n",
    "    'informer',\n",
    "    'prophet',\n",
    "    'tuned_salient2',\n",
    "    #Ensembles\n",
    "    'linear_ensemble',  \n",
    "    'online_learning'\n",
    "]\n",
    "\n",
    "# Rodeo experiment model names\n",
    "rodeo_experiment_models = [\n",
    "    # Baselines\n",
    "    \"climatology\",   \n",
    "    'deb_cfsv2',\n",
    "    'persistence',\n",
    "    # Toolkit \n",
    "    'tuned_climpp',\n",
    "    'tuned_cfsv2pp',\n",
    "    'perpp',\n",
    "    #Learning\n",
    "    'autoknn',\n",
    "    'tuned_localboosting',\n",
    "    'multillr',\n",
    "    'prophet',\n",
    "    'tuned_salient2',\n",
    "    #Ensembles\n",
    "    'linear_ensemble_localFalse_dynamicFalse_stepFalse_LtCtD',\n",
    "    'linear_ensemble_localFalse_dynamicFalse_stepFalse_AMLPtCtDtKtS',  \n",
    "    'online_learning-ah_rpNone_R1_recent_g_SC_LtCtD',\n",
    "    'online_learning-ah_rpNone_R1_recent_g_SC_AMLPtCtDtKtS'\n",
    "]\n",
    "\n",
    "# Salient experiment model names\n",
    "salient_experiment_models = [\n",
    "    # Baselines   \n",
    "    'deb_cfsv2',\n",
    "    # Toolkit \n",
    "    'tuned_cfsv2pp',\n",
    "    #Learning\n",
    "    'tuned_salient2',\n",
    "]\n",
    "\n",
    "\n",
    "# ECMWF experiment model names\n",
    "ecmwf_experiment_models = [\n",
    "    # Baselines\n",
    "    \"climatology\", \n",
    "    'deb_cfsv2',\n",
    "    'persistence',\n",
    "    # Toolkit \n",
    "    'tuned_climpp',\n",
    "    'tuned_cfsv2pp',\n",
    "    'perpp',\n",
    "    # ECMWF\n",
    "    'ecmwf-years20_leads15-15_lossmse_forecastc_debiasp+c',\n",
    "    'ecmwf-years20_leads15-15_lossmse_forecastp_debiasp+c',\n",
    "    # Ensembles\n",
    "    \"online_learning\", \n",
    "    \"linear_ensemble\" \n",
    "]\n",
    "\n",
    "# De-biasing experiment model names\n",
    "debias_experiment_models = [\n",
    "    # Baselines\n",
    "    \"raw_ccsm4\", \n",
    "    \"raw_cfsv2\",\n",
    "    \"raw_geos_v2p1\",\n",
    "    \"raw_nesm\",\n",
    "    \"raw_fimr1p1\",\n",
    "    \"raw_gefs\",\n",
    "    \"raw_gem\",\n",
    "    \"raw_ecmwf\",\n",
    "    # Ensembles \n",
    "    \"abc_ccsm4\",\n",
    "    \"abc_cfsv2\",\n",
    "    \"abc_geos_v2p1\",\n",
    "    \"abc_nesm\",\n",
    "    \"abc_fimr1p1\",\n",
    "    \"abc_gefs\",\n",
    "    \"abc_gem\", \n",
    "    \"abc_ecmwf\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Dictionaries mapping all model names and tasks to their display names\n",
    "#\n",
    "\n",
    "east_tasks = {\n",
    "    \"east_tmp2m_34w\": \"Temp. weeks 3-4\",\n",
    "    \"east_tmp2m_56w\": \"Temp. weeks 5-6\",\n",
    "    \"east_precip_34w\": \"Precip. weeks 3-4\",\n",
    "    \"east_precip_56w\": \"Precip. weeks 5-6\"\n",
    "}\n",
    "\n",
    "contest_tasks = {\n",
    "    \"contest_tmp2m_34w\": \"Temp. weeks 3-4\",\n",
    "    \"contest_tmp2m_56w\": \"Temp. weeks 5-6\",\n",
    "    \"contest_precip_34w\": \"Precip. weeks 3-4\",\n",
    "    \"contest_precip_56w\": \"Precip. weeks 5-6\"\n",
    "}\n",
    "us_tasks = {\n",
    "    \"us_tmp2m_34w\": \"Temp. weeks 3-4\",\n",
    "    \"us_tmp2m_56w\": \"Temp. weeks 5-6\",\n",
    "    \"us_precip_34w\": \"Precip. weeks 3-4\",\n",
    "    \"us_precip_56w\": \"Precip. weeks 5-6\",   \n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in all metrics for all tasks and all models\n",
    "Reads metrics, generates a summary of missing data, and produces the `all_metrics` dictionary to be used in further analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Generate a dictionary with metric values for all models and every combination of gt_id, \n",
    "horizon, and target dates\n",
    "\"\"\"\n",
    "\n",
    "all_metrics = {}\n",
    "\n",
    "# Get metrics for main experiment, rodeo experiment, salient experiment and ecmwf experiment\n",
    "for metric, gt_id, horizon, target_dates in \\\n",
    "        [x for x in product(['rmse', 'skill'], us_1_5_gt_ids, horizons, ['std_paper_forecast'])]:\n",
    "        #[x for x in product(['rmse', 'skill'], us_gt_ids, horizons, ['std_paper'])] \\\n",
    "        #+[x for x in product(['rmse'], contest_gt_ids, horizons, ['std_contest'])] \\\n",
    "        #+[x for x in product(['rmse'], contest_gt_ids, horizons, ['std_paper'])] \\\n",
    "        #+[x for x in product(['rmse', 'skill'], us_1_5_gt_ids, horizons, ['std_ecmwf'])]: \n",
    "   \n",
    "    \n",
    "    #Set model names   \n",
    "    if 'us' in gt_id:\n",
    "        model_names = ecmwf_experiment_models if '1.5x1.5' in gt_id else debias_experiment_models\n",
    "        model_names_str = 'ecmwf_experiment_models' if '1.5x1.5' in gt_id else 'debias_experiment_models'\n",
    "    elif 'contest' in gt_id:\n",
    "        model_names = rodeo_experiment_models if 'contest' in target_dates else salient_experiment_models\n",
    "        model_names_str = 'rodeo_experiment_models' if 'contest' in target_dates else 'salient_experiment_models'\n",
    "    else:\n",
    "        model_names = all_models\n",
    "        model_names_str = 'all_models'\n",
    "        \n",
    "\n",
    "    \n",
    "    model_names = debias_experiment_models\n",
    "    # Get task\n",
    "    task = f\"{gt_id}_{horizon}\"\n",
    "\n",
    "    #display(Markdown(f\"### Loading metric {metric} for task {task} and dates {target_dates}\"))\n",
    "    display(Markdown(f\"### {model_names_str}: {metric}, {task}, {target_dates}\"))\n",
    "\n",
    "    # Get all metrics\n",
    "    df = get_metrics_df(gt_id, horizon, metric, target_dates, model_names=model_names)\n",
    "    # No models exist for this task    \n",
    "    if df is None: \n",
    "        continue\n",
    "\n",
    "    # Add yearly and quarterly columns to the dataframe\n",
    "    df = add_groupby_cols(df, horizon=horizon)\n",
    "\n",
    "    all_metrics[(metric, task, target_dates)] = copy.copy(df)\n",
    "    #print(all_metrics)\n",
    "\n",
    "    if metric in ['rmse', 'skill']:\n",
    "        key = (metric, task, target_dates)\n",
    "        try:        \n",
    "            missing_df = all_metrics[key].loc[(all_metrics[key][model_names].isnull().any(axis=1)),:]\n",
    "        except:        \n",
    "            missing_df = all_metrics[key].loc[(all_metrics[key].isnull().any(axis=1)),:]            \n",
    "        if missing_df.shape[0] != 0:\n",
    "            True\n",
    "            display(Markdown(f\"#### Missing metrics\"))\n",
    "            display(missing_df)    \n",
    "        else:\n",
    "            printf(\"All metrics present.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 1: Raw vs. ABC models\n",
    "### Bar plots \n",
    "This code produces maps to compare models' skill over the evaluation period 2018-2021. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_context(\"notebook\", font_scale=2.5, rc={\"lines.linewidth\": 0.5})\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "sns.set_palette(\"Paired\")\n",
    "sns.set(font_scale = 1.5, rc={'font.weight': 'bold', 'figure.facecolor':'white', \"lines.linewidth\": 0.75})\n",
    "sns.set_style(\"whitegrid\")#, {'legend.frameon':True})\n",
    "\n",
    "def barplot_rawabc(model_names, gt_id, horizon, metric, target_dates, show=True): \n",
    "    target_dates_objs = get_target_dates(target_dates)\n",
    "    target_dates_start = datetime.strftime(target_dates_objs[0], '%Y-%m-%d')\n",
    "    target_dates_end = datetime.strftime(target_dates_objs[-1], '%Y-%m-%d')\n",
    "    target_dates_str = target_dates.replace('cold_','Cold wave, ').replace('texas','Texas').replace('gl','Great Lakes').replace('ne','New England')\n",
    "    figure_models_missing56w = [\n",
    "    \"raw_fimr1p1\",\n",
    "    \"raw_gefs\",\n",
    "    \"raw_gem\",\n",
    "    \"abc_fimr1p1\",\n",
    "    \"abc_gefs\",\n",
    "    \"abc_gem\",    \n",
    "    ]\n",
    "    task = f'{gt_id}_{horizon}'\n",
    "    if horizon == '56w':\n",
    "        model_names = [m for m in model_names if m not in figure_models_missing56w]\n",
    "    df_barplot = pd.DataFrame(columns=['start_date', metric, 'debias_method', 'model'])\n",
    "    for i, m in enumerate(model_names):\n",
    "    #     print(m)\n",
    "        sn = get_selected_submodel_name(m, gt_id, horizon)\n",
    "        f = os.path.join('eval', 'metrics', m, 'submodel_forecasts', sn, task, f'{metric}-{task}-{target_dates}.h5')\n",
    "        if os.path.isfile(f):\n",
    "            df = pd.read_hdf(f)\n",
    "            df['debias_method'] = 'Dynamical' if m.split('_')[0]=='raw' else 'ABC'\n",
    "            df['model'] = all_model_names[f\"raw_{'_'.join(m.split('_')[1:])}\"]\n",
    "            df_barplot = df_barplot.append(df)\n",
    "        else:\n",
    "            printf(f\"Metrics file missing for {metric} {m} {task}\")\n",
    "    df_barplot\n",
    "    ax = sns.barplot(x=\"model\", y=metric, hue=\"debias_method\", data=df_barplot, ci=95, capsize=0.1, palette={\n",
    "    'Dynamical': 'red',\n",
    "    'ABC': 'skyblue'\n",
    "})\n",
    "    fig_title = f\"{task.replace('_','').replace('precip',' Precipitation').replace('tmp2m',' Temperature').replace('us','U.S.')}\"\n",
    "    fig_title = fig_title.replace('56w', ', weeks 5-6').replace('34w', ', weeks 3-4').replace('12w', ', weeks 1-2').replace('1.5x1.5', '')\n",
    "    fig_title = f\"{fig_title}\\n\"#{target_dates_str}: {target_dates_start} to {target_dates_end}\"\n",
    "    ax.set_title(fig_title, weight='bold')\n",
    "    if '56w' in horizon:\n",
    "        ax.set_xticklabels(ax.get_xticklabels(), fontdict={'size': 16})#, rotation = 90)\n",
    "    else:\n",
    "        ax.set_xticklabels(ax.get_xticklabels(), fontdict={'size': 11})#, rotation = 90)\n",
    "    ax.set(xlabel=None)\n",
    "    ax.set_ylabel('Skill', fontdict={'weight': 'bold'})\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    ax.legend(handles=handles[0:], labels=labels[0:], frameon=True, edgecolor='white', framealpha=1)\n",
    "    if target_dates.startswith('std_'):\n",
    "        if 'precip' in gt_id and '12' not in horizon:\n",
    "            ax. set(ylim=(-0.025, 0.3))\n",
    "        elif 'precip' in gt_id and '12' in horizon:\n",
    "            ax. set(ylim=(-0.025, 0.65))\n",
    "        elif 'tmp2m' in gt_id and '12' not in horizon:\n",
    "            ax. set(ylim=(-0.03, 0.5))\n",
    "        elif 'tmp2m' in gt_id and '12' in horizon:\n",
    "            ax. set(ylim=(-0.03, 0.9))\n",
    "    fig = ax.get_figure()\n",
    "    out_file = f\"subseasonal_toolkit/viz/barplot_{metric}_{task}_{target_dates}.pdf\"\n",
    "    fig.savefig(out_file) \n",
    "    subprocess.call(\"chmod a+w \"+out_file, shell=True)\n",
    "    subprocess.call(\"chown $USER:sched_mit_hill \"+out_file, shell=True)\n",
    "    print(f\"\\nFigure saved: {out_file}\\n\")\n",
    "    if show is False:\n",
    "        fig.clear()\n",
    "        plt.close(fig)  \n",
    "\n",
    "figure_models = [\n",
    "    # Baselines\n",
    "    \"raw_ccsm4\", \n",
    "    \"raw_cfsv2\",\n",
    "    \"raw_geos_v2p1\",\n",
    "    \"raw_nesm\",\n",
    "    \"raw_fimr1p1\",\n",
    "    \"raw_gefs\",\n",
    "    \"raw_gem\",\n",
    "    \"raw_ecmwf\",\n",
    "    # Ensembles \n",
    "    \"abc_ccsm4\",\n",
    "    \"abc_cfsv2\",\n",
    "    \"abc_geos_v2p1\",\n",
    "    \"abc_nesm\",\n",
    "    \"abc_fimr1p1\",\n",
    "    \"abc_gefs\",\n",
    "    \"abc_gem\", \n",
    "    \"abc_ecmwf\",\n",
    "]\n",
    "\n",
    "gt_id = 'us_precip_1.5x1.5'\n",
    "horizon = '56w'\n",
    "metric = 'skill'\n",
    "target_dates = 'std_paper_forecast'\n",
    "\n",
    "barplot_rawabc(model_names=figure_models, gt_id=gt_id, horizon=horizon, metric=metric, target_dates=target_dates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 2: Raw vs. Debiased and ABC models\n",
    "### lat_lon_skill map\n",
    "This code produces maps to analyze skill for different models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure_target_dates = 'std_paper_forecast'\n",
    "figure_models = [\n",
    "    # Baselines\n",
    "    \"raw_cfsv2\",\n",
    "    \"raw_ecmwf\",\n",
    "    # Standard de-biasing\n",
    "    \"deb_cfsv2\",\n",
    "    \"deb_ecmwf\",\n",
    "    # Ensembles \n",
    "    \"abc_cfsv2\",\n",
    "    \"abc_ecmwf\",\n",
    "]\n",
    "\n",
    "#RDA: models for which Raw, Debiased and Abc versions are available\n",
    "metric_dfs_rda = {}\n",
    "for gt_id, horizon in product(us_1_5_gt_ids, horizons):\n",
    "    task = f\"{gt_id}_{horizon}\"\n",
    "    display(Markdown(f\"#### Getting metrics for {gt_id} {horizon}\"))\n",
    "    metric_dfs_rda[task] = get_models_metric_lat_lon(gt_id=gt_id, horizon=horizon, target_dates=figure_target_dates, metrics = ['lat_lon_skill','skill'], model_names=figure_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure_model_names = [\"raw_cfsv2\", \"deb_cfsv2\", \"abc_cfsv2\"]\n",
    "\n",
    "# Figure parameter values\n",
    "figure_gt_ids = us_1_5_gt_ids\n",
    "figure_horizons = horizons\n",
    "figure_metric = 'lat_lon_skill'\n",
    "figure_mean_metric_df = metric_dfs_rda #None\n",
    "figure_show = True\n",
    "\n",
    "#for gt_id in figure_gt_ids:\n",
    "for gt_id in figure_gt_ids:\n",
    "    plot_metric_maps(metric_dfs_rda, model_names=figure_model_names,\n",
    "                         gt_ids=[gt_id],\n",
    "                         horizons=figure_horizons,\n",
    "                         metric=figure_metric,\n",
    "                         target_dates=figure_target_dates,\n",
    "                         mean_metric_df=figure_mean_metric_df,\n",
    "                         show=figure_show, \n",
    "                         scale_type='linear',\n",
    "                         CB_colors_customized=[\"white\", \"#dede00\", \"#ff7f00\", \"blueviolet\", \"indigo\", \"yellowgreen\", \"lightgreen\", \"darkgreen\"],\n",
    "                         CB_minmax = (0, 85))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure_model_names = [\"raw_ecmwf\", \"deb_ecmwf\", \"abc_ecmwf\"]\n",
    "\n",
    "# Figure parameter values\n",
    "figure_gt_ids = us_1_5_gt_ids\n",
    "figure_horizons = horizons\n",
    "figure_metric = 'lat_lon_skill'\n",
    "figure_mean_metric_df = metric_dfs_rda #None\n",
    "figure_show = True\n",
    "\n",
    "#for gt_id in figure_gt_ids:\n",
    "for gt_id in figure_gt_ids:\n",
    "    plot_metric_maps(metric_dfs_rda, model_names=figure_model_names,\n",
    "                         gt_ids=[gt_id],\n",
    "                         horizons=figure_horizons,\n",
    "                         metric=figure_metric,\n",
    "                         target_dates=figure_target_dates,\n",
    "                         mean_metric_df=figure_mean_metric_df,\n",
    "                         show=figure_show, \n",
    "                         scale_type='linear',\n",
    "                         CB_colors_customized=[\"white\", \"#dede00\", \"#ff7f00\", \"blueviolet\", \"indigo\", \"yellowgreen\", \"lightgreen\", \"darkgreen\"],\n",
    "                         CB_minmax = (0, 85))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 3: Raw vs. ABC models\n",
    "### Bias map (lat_lon_error)\n",
    "This code produces maps to analyze bias for different models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure_target_dates = 'std_paper_forecast'\n",
    "figure_models = [\n",
    "    # Baselines\n",
    "    \"raw_cfsv2\",\n",
    "#     \"raw_ecmwf\",\n",
    "#     # Standard de-biasing\n",
    "#     \"deb_cfsv2\",\n",
    "#     \"deb_ecmwf\",\n",
    "    # Ensembles \n",
    "    \"abc_cfsv2\",\n",
    "#     \"abc_ecmwf\",\n",
    "]\n",
    "\n",
    "#RDA: models for which Raw, Debiased and Abc versions are available\n",
    "metric_dfs_rda = {}\n",
    "for gt_id, horizon in product(us_1_5_gt_ids, horizons):\n",
    "    task = f\"{gt_id}_{horizon}\"\n",
    "    display(Markdown(f\"#### Getting metrics for {gt_id} {horizon}\"))\n",
    "    metric_dfs_rda[task] = get_models_metric_lat_lon(gt_id=gt_id, horizon=horizon, target_dates=figure_target_dates, metrics = ['lat_lon_error'], model_names=figure_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure_model_names = [\"raw_cfsv2\", \"abc_cfsv2\"]\n",
    "\n",
    "# Figure parameter values\n",
    "figure_gt_ids = us_1_5_gt_ids\n",
    "figure_horizons = horizons\n",
    "figure_metric = 'lat_lon_error'\n",
    "figure_mean_metric_df = None# metric_dfs_rda#None\n",
    "figure_show = True\n",
    "\n",
    "#for gt_id in figure_gt_ids:\n",
    "for gt_id in figure_gt_ids:\n",
    "    if 'tmp2m' in gt_id:\n",
    "            CB_colors_customized=['blue','dodgerblue','lightskyblue',\"white\",'red','firebrick','darkred']\n",
    "            CB_minmax = (-4, 4)\n",
    "    else:\n",
    "            CB_colors_customized=['saddlebrown','peru',\"white\",'yellowgreen','green']\n",
    "            CB_minmax = (-15, 15)\n",
    "    plot_metric_maps(metric_dfs_rda, model_names=figure_model_names,\n",
    "                         gt_ids=[gt_id],\n",
    "                         horizons=figure_horizons,\n",
    "                         metric=figure_metric,\n",
    "                         target_dates=figure_target_dates,\n",
    "                         mean_metric_df=figure_mean_metric_df,\n",
    "                         show=figure_show, \n",
    "                         scale_type='linear',\n",
    "                         CB_colors_customized=CB_colors_customized,\n",
    "                         CB_minmax = CB_minmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True:\n",
    "    figure_target_dates = 'std_paper_forecast'#'cold_gl'\n",
    "    figure_models = [\n",
    "        # Baselines\n",
    "    #     \"raw_cfsv2\",\n",
    "        \"raw_ecmwf\",\n",
    "    #     # Standard de-biasing\n",
    "    #     \"deb_cfsv2\",\n",
    "    #     \"deb_ecmwf\",\n",
    "        # Ensembles \n",
    "    #     \"abc_cfsv2\",\n",
    "        \"abc_ecmwf\",\n",
    "    ]\n",
    "\n",
    "    #RDA: models for which Raw, Debiased and Abc versions are available\n",
    "    metric_dfs_rda = {}\n",
    "    for gt_id, horizon in product(us_1_5_gt_ids, horizons):\n",
    "        task = f\"{gt_id}_{horizon}\"\n",
    "        display(Markdown(f\"#### Getting metrics for {gt_id} {horizon}\"))\n",
    "        metric_dfs_rda[task] = get_models_metric_lat_lon(gt_id=gt_id, horizon=horizon, target_dates=figure_target_dates, metrics = ['lat_lon_error'], model_names=figure_models)\n",
    "        \n",
    "        \n",
    "figure_model_names = [\"raw_ecmwf\", \"abc_ecmwf\"]\n",
    "\n",
    "# Figure parameter values\n",
    "figure_gt_ids = us_1_5_gt_ids\n",
    "figure_horizons = horizons\n",
    "figure_metric = 'lat_lon_error'\n",
    "figure_mean_metric_df = None\n",
    "figure_show = True\n",
    "\n",
    "#for gt_id in figure_gt_ids:\n",
    "for gt_id in figure_gt_ids:\n",
    "    if 'tmp2m' in gt_id:\n",
    "            CB_colors_customized=['blue','dodgerblue','lightskyblue',\"white\",'red','firebrick','darkred']\n",
    "            CB_minmax = (-4, 4)\n",
    "    else:\n",
    "            CB_colors_customized=['saddlebrown','peru',\"white\",'yellowgreen','green']\n",
    "            CB_minmax = (-15, 15)\n",
    "    plot_metric_maps(metric_dfs_rda, model_names=figure_model_names,\n",
    "                         gt_ids=[gt_id],\n",
    "                         horizons=figure_horizons,\n",
    "                         metric=figure_metric,\n",
    "                         target_dates=figure_target_dates,\n",
    "                         mean_metric_df=figure_mean_metric_df,\n",
    "                         show=figure_show, \n",
    "                         scale_type='linear',\n",
    "                         CB_colors_customized=CB_colors_customized,\n",
    "                         CB_minmax = CB_minmax)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
