{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ABC\n",
    "\n",
    "Adaptive Bias Correction combining dynamical model forecasts, lagged measurements, and climatology."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "from subseasonal_toolkit.utils.notebook_util import isnotebook\n",
    "if isnotebook():\n",
    "    # Autoreload packages that are modified\n",
    "    %load_ext autoreload\n",
    "    %autoreload 2\n",
    "else:\n",
    "    from argparse import ArgumentParser\n",
    "\n",
    "# Imports \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import *\n",
    "import sys\n",
    "import json\n",
    "import subprocess\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import shutil\n",
    "from datetime import datetime, timedelta\n",
    "from filelock import FileLock\n",
    "from pkg_resources import resource_filename\n",
    "from ttictoc import tic, toc\n",
    "from subseasonal_toolkit.utils.general_util import printf\n",
    "from subseasonal_toolkit.utils.eval_util import get_target_dates, get_named_targets\n",
    "from subseasonal_toolkit.utils.models_util import get_selected_submodel_name\n",
    "from subseasonal_toolkit.models.linear_ensemble.attributes import get_submodel_name as get_linear_ensemble_sn\n",
    "from subseasonal_toolkit.models.abc.abc_util import *\n",
    "pd.set_option('display.max_rows', None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Specify model parameters\n",
    "#\n",
    "if not isnotebook():\n",
    "    # If notebook run as a script, parse command-line arguments\n",
    "    parser = ArgumentParser()\n",
    "    parser.add_argument(\"pos_vars\",nargs=\"*\")  # gt_id and horizon                                                                                  \n",
    "    parser.add_argument('--target_dates', '-t', default=\"std_contest\")\n",
    "    parser.add_argument('--forecast', '-f', default=\"cfsv2\", \n",
    "                        help=\"include the forecasts of this dynamical model as features\")\n",
    "    parser.add_argument('--ensemble', '-e', nargs='+', default=['linear_ensemble'],\n",
    "                        help=\"ensembling algorithm, either 'linear_ensemble', 'online_learning' or both\")\n",
    "    parser.add_argument('--cmd_prefix', '-c', default=\"python\")\n",
    "    args, opt = parser.parse_known_args()\n",
    "    \n",
    "    # Assign variables                                                                                                                                     \n",
    "    gt_id = args.pos_vars[0] # \"contest_precip\" or \"contest_tmp2m\"                                                                            \n",
    "    horizon = args.pos_vars[1] # \"34w\" or \"56w\"                                                                                        \n",
    "    target_dates = args.target_dates\n",
    "    forecast = args.forecast\n",
    "    ensemble_models = args.ensemble\n",
    "    cmd_prefix = args.cmd_prefix\n",
    "else:\n",
    "    # Otherwise, specify arguments interactively \n",
    "    gt_id = \"us_precip_1.5x1.5\"\n",
    "    horizon = \"34w\"\n",
    "    target_dates = \"std_paper_forecast\"\n",
    "    forecast = \"ecmwf\"\n",
    "    ensemble_models = [\"linear_ensemble\"]#, \"online_learning\"]\n",
    "    cmd_prefix = \"python\"\n",
    "\n",
    "# Get forecasting task\n",
    "task = f\"{gt_id}_{horizon}\"\n",
    "# Get list of ensemble member model names\n",
    "if \"ecmwf:\" in forecast:\n",
    "    # ECMWF submodel requested; skip individual ensemble member steps\n",
    "    ensemble_members = []\n",
    "elif horizon == '12w':\n",
    "    ensemble_members = [pp_name, perpp_name]\n",
    "else:\n",
    "    ensemble_members = ['tuned_climpp', pp_name, perpp_name]\n",
    "\n",
    "# Get list of target date objects\n",
    "target_date_objs = pd.Series(get_target_dates(date_str=target_dates,horizon=horizon))\n",
    "    \n",
    "# Process command-line arguments\n",
    "metrics_prefix = cmd_prefix\n",
    "if cmd_prefix != \"python\":\n",
    "    # Add slurm resource requirements\n",
    "    metrics_prefix += \" --memory 8 --cores 1 --hours 0 --minutes 10\"\n",
    "metrics_script = resource_filename(__name__, os.path.join(\"..\",\"..\",\"batch_metrics.py\"))\n",
    "job_dependency_model = \"\"\n",
    "job_dependency_metric = \"\"\n",
    "job_dependency_ensemble = \"\"\n",
    "cmd_suffix = \"\"\n",
    "cluster_str = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate ensemble members forecasts\n",
    "for i, m in enumerate(ensemble_members):\n",
    "    printf(f\"\\nGenerating forecasts for {m}:\")\n",
    "    model = m.replace('tuned_','') if m.startswith('tuned_') else m\n",
    "        \n",
    "    # Set command prefix and suffix\n",
    "    if cmd_prefix != \"python\":\n",
    "        cluster_str = get_cluster_params(model, gt_id, horizon, target_dates)\n",
    "        # Keep track of job ID to specify job dependencies\n",
    "        cmd_suffix = \"| tail -n 1 | awk '{print $NF}'\"\n",
    "    \n",
    "    \n",
    "    # Skip if model metrics already exist\n",
    "    if metric_file_exists(m, task, target_dates):\n",
    "        printf(f\"Skipping {m} -- metrics already exist for {target_dates}\\n\")\n",
    "        continue\n",
    "    elif m.startswith('tuned_'):\n",
    "        predict_script = resource_filename(__name__, os.path.join(\"..\",\"..\",\"models\",\"tuner\",\"batch_predict.py\"))\n",
    "        cmd = f\"{cmd_prefix} {cluster_str} \\\"{predict_script}\\\" {gt_id} {horizon} -t {target_dates} -mn {model} -y 3 -m None {cmd_suffix}\"\n",
    "    else:\n",
    "        #args_str = get_sn_params(model, task, target_dates)\n",
    "        predict_script = resource_filename(__name__, os.path.join(\"..\",\"..\",\"models\",model,\"batch_predict.py\"))\n",
    "        cmd = f\"{cmd_prefix} {cluster_str} \\\"{predict_script}\\\" {gt_id} {horizon} -t {target_dates} -y all -m None {cmd_suffix}\"\n",
    "\n",
    "    printf(f\"Running batch predict: \\n{cmd}\")\n",
    "    if cmd_prefix == \"python\":\n",
    "        subprocess.call(cmd, shell=True)\n",
    "    else:\n",
    "        # Store job ID to ensure batch metric call runs afterwards\n",
    "        process = subprocess.run(cmd, check=True, stdout=subprocess.PIPE, universal_newlines=True, shell=True)\n",
    "        job_id = process.stdout.rstrip()\n",
    "        job_dependency_model=f\"-d {job_id}\" \n",
    "\n",
    "    \n",
    "    #Run dependent job for metric generation on named target_date ranges\n",
    "    if True:#target_dates in get_named_targets():\n",
    "        metrics = \"rmse score skill lat_lon_rmse\"\n",
    "        metrics_args = f\"{gt_id} {horizon} -mn {m} -t {target_dates} -m {metrics}\"\n",
    "        metrics_cmd=f\"{metrics_prefix} {job_dependency_model} {metrics_script} {metrics_args} {cmd_suffix}\"\n",
    "        printf(f\"Running batch metrics: \\n{metrics_cmd}\\n\")\n",
    "        if cmd_prefix == \"python\":\n",
    "            subprocess.call(metrics_cmd, shell=True)\n",
    "        else:\n",
    "            # Store job ID to ensure batch metric call runs afterwards\n",
    "            process = subprocess.run(metrics_cmd, check=True, stdout=subprocess.PIPE, universal_newlines=True, shell=True)\n",
    "            job_id = process.stdout.rstrip()\n",
    "            job_dependency_metric=f\"-d {job_id}\" if i==0 else f\"{job_dependency_model},{job_id}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run ensembling model\n",
    "for model in ensemble_models:\n",
    "    printf(f\"Running ensembling via {model}:\")\n",
    "\n",
    "    # Set command prefix and suffix\n",
    "    if cmd_prefix != \"python\":\n",
    "        cluster_str = get_cluster_params(model, gt_id, horizon, target_dates)\n",
    "        # Keep track of job ID to specify job dependencies\n",
    "        cmd_suffix = \"| tail -n 1 | awk '{print $NF}'\"\n",
    "\n",
    "    predict_script = resource_filename(__name__, os.path.join(\"..\", \"..\", \"models\",model,\"batch_predict.py\"))\n",
    "    predict_args = f\"{gt_id} {horizon} -t {target_dates} -f {forecast}\"\n",
    "    cmd = f\"{cmd_prefix} {cluster_str} {job_dependency_metric} \\\"{predict_script}\\\" {predict_args} {cmd_suffix}\"\n",
    "\n",
    "    printf(f\"Running ensemble batch predict: \\n{cmd}\")\n",
    "    if cmd_prefix == \"python\":\n",
    "        subprocess.call(cmd, shell=True)\n",
    "    else:\n",
    "        # Store job ID to ensure batch metric call runs afterwards\n",
    "        process = subprocess.run(cmd, check=True, stdout=subprocess.PIPE, universal_newlines=True, shell=True)\n",
    "        job_id = process.stdout.rstrip()\n",
    "        job_dependency_ensemble=f\"-d {job_id}\"\n",
    "\n",
    "    #Run dependent job for metric generation on named target_date ranges\n",
    "    if ensemble_members:#target_dates in get_named_targets():\n",
    "        metrics = \"rmse score skill lat_lon_rmse\"\n",
    "        sn = get_linear_ensemble_sn(model_names=','.join(ensemble_members))\n",
    "        metrics_args = f\"{gt_id} {horizon} -mn abc_{forecast} -sn {sn} -t {target_dates} -m {metrics}\"\n",
    "        metrics_cmd=f\"{metrics_prefix} {job_dependency_ensemble} {metrics_script} {metrics_args} {cmd_suffix}\"\n",
    "        printf(f\"Running ensemble batch metrics: \\n{metrics_cmd}\\n\\n\")\n",
    "        subprocess.call(metrics_cmd, shell=True)\n",
    "\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
