{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deterministic to probabilistic forecasting\n",
    "\n",
    "### Produces probabilistic forecasts from a collection of deterministic forecasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure notebook is being run from base repository directory\n",
    "import os, sys\n",
    "from subseasonal_toolkit.utils.notebook_util import isnotebook\n",
    "if isnotebook():\n",
    "    # Autoreload packages that are modified\n",
    "    %load_ext autoreload\n",
    "    %autoreload 2\n",
    "else:\n",
    "    from argparse import ArgumentParser\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import shutil\n",
    "from datetime import datetime\n",
    "from pkg_resources import resource_filename\n",
    "from subseasonal_data.utils import get_measurement_variable\n",
    "from subseasonal_toolkit.utils.general_util import printf, make_directories, tic, toc\n",
    "from subseasonal_toolkit.utils.models_util import (get_submodel_name, start_logger, \n",
    "                                                   log_params, get_forecast_filename,\n",
    "                                                   save_forecasts, get_d2p_submodel_names)\n",
    "from subseasonal_toolkit.utils.eval_util import get_target_dates\n",
    "\n",
    "from subseasonal_data import data_loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Specify model parameters\n",
    "#\n",
    "if not isnotebook():\n",
    "    # If notebook run as a script, parse command-line arguments\n",
    "    parser = ArgumentParser()\n",
    "    parser.add_argument(\"pos_vars\",nargs=\"*\")  # gt_id and horizon \n",
    "    parser.add_argument('--model_name', '-mn', default=\"raw_ecmwf\")                                                                                 \n",
    "    parser.add_argument('--target_dates', '-t', default=\"std_paper_forecast\")\n",
    "    parser.add_argument('--first_year', '-fy', default=1981, type=int,\n",
    "                        help=\"first year of climatological period\")\n",
    "    parser.add_argument('--last_year', '-ly', default=2010, type=int,\n",
    "                        help=\"last year of climatological period\")\n",
    "    args = parser.parse_args()\n",
    "    \n",
    "    # Assign variables                                                                                                                                     \n",
    "    gt_id = args.pos_vars[0] # e.g., \"contest_precip\" or \"contest_tmp2m\"                                                                            \n",
    "    horizon = args.pos_vars[1] # e.g., \"12w\", \"34w\", or \"56w\"    \n",
    "    model_name = args.model_name\n",
    "    target_dates = args.target_dates\n",
    "    first_year = args.first_year\n",
    "    last_year = args.last_year\n",
    "else:\n",
    "    # Otherwise, specify arguments interactively\n",
    "    gt_id = \"us_tmp2m_p1_1.5x1.5\" \n",
    "    horizon = \"34w\"\n",
    "    model_name = \"raw_ecmwf\" \n",
    "    target_dates = \"std_paper_forecast\"\n",
    "    first_year = 1981\n",
    "    last_year = 2010\n",
    "\n",
    "#\n",
    "# Process model parameters\n",
    "#\n",
    "# Record output model name \n",
    "output_model_name = f\"d2p_{model_name}\"\n",
    "task = f\"{gt_id}_{horizon}\"\n",
    "\n",
    "# Prepare a directory to store d2p model attributes and configuration files\n",
    "src_dir = resource_filename(__name__, os.path.join(\".\"))\n",
    "dst_dir = resource_filename(__name__, \n",
    "                            os.path.join(\"..\",\"..\",\"models\", output_model_name))\n",
    "if not os.path.exists(dst_dir):\n",
    "    tic()\n",
    "    printf(f'\\nCreating {dst_dir}')\n",
    "    make_directories(dst_dir)\n",
    "    # copy attributes and selected submodel files to output model folder\n",
    "    shutil.copy(os.path.join(src_dir, \"attributes.py\"), \n",
    "                os.path.join(dst_dir, \"attributes.py\"))\n",
    "    shutil.copy(os.path.join(src_dir, \"selected_submodel.json\"), \n",
    "                os.path.join(dst_dir, \"selected_submodel.json\"))\n",
    "    # update MODEL_NAME in the attribute file\n",
    "    filename = os.path.join(dst_dir, \"attributes.py\")\n",
    "    with open(filename, \"r\") as f:\n",
    "        newText=f.read().replace(\"d2p\", output_model_name)\n",
    "    with open(filename, \"w\") as f:\n",
    "        f.write(newText)\n",
    "    toc()\n",
    "    \n",
    "# Identify submodel name for new output model \n",
    "submodel_name = get_submodel_name(\n",
    "    output_model_name, \n",
    "    first_year=first_year, last_year=last_year)\n",
    "\n",
    "# Create directory for storing forecasts if one does not already exist\n",
    "out_dir = os.path.join(\"models\", output_model_name, \"submodel_forecasts\", \n",
    "                       submodel_name, f\"{gt_id}_{horizon}\")\n",
    "if not os.path.exists(out_dir):\n",
    "    make_directories(out_dir)\n",
    "    \n",
    "if not isnotebook():\n",
    "    # Save output to log file\n",
    "    logger = start_logger(model=output_model_name,submodel=submodel_name,gt_id=gt_id,\n",
    "                          horizon=horizon,target_dates=target_dates)\n",
    "    # Store parameter values in log\n",
    "    params_names = ['gt_id', 'horizon', 'model_name', \n",
    "                    'target_dates', 'first_year', 'last_year']\n",
    "    params_values = [eval(param) for param in params_names]\n",
    "    log_params(params_names, params_values)\n",
    "\n",
    "# Select target dates\n",
    "target_date_objs = get_target_dates(target_dates, horizon=horizon)\n",
    "#print(target_date_objs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Identify target tercile and associated deterministic gt_id\n",
    "#\n",
    "if \"_p1\" in gt_id:\n",
    "    # Load tercile 1 and check if forecasts are no larger\n",
    "    load_tercile = 1\n",
    "    det_gt_id = gt_id.replace('_p1', '')\n",
    "elif \"_p3\" in gt_id:\n",
    "    # Load tercile 2 and check if forecasts are greater\n",
    "    load_tercile = 2\n",
    "    det_gt_id = gt_id.replace('_p3', '')\n",
    "else:\n",
    "    raise ValueError(f\"unsupported probabilistic gt_id {gt_id}\")\n",
    "\n",
    "#\n",
    "# Load climatological terciles\n",
    "#\n",
    "printf(f\"\\nLoading tercile data\")\n",
    "tic()\n",
    "var = get_measurement_variable(det_gt_id)\n",
    "terc_data = data_loaders.get_tercile(\n",
    "    det_gt_id, tercile=load_tercile, first_year=first_year, \n",
    "    last_year=last_year).loc[:,[\"start_date\",\"lat\",\"lon\",var]]\n",
    "terc_data = terc_data.set_index(\n",
    "    [\"start_date\",\"lat\",\"lon\"]).squeeze().unstack('start_date')\n",
    "# Use month-day combinations as column indices\n",
    "terc_data.columns = [(d.month,d.day) for d in terc_data.columns]\n",
    "toc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of deterministic submodels to ensemble in forming\n",
    "# probabilistic forecasts\n",
    "det_submodel_names = get_d2p_submodel_names(model_name, det_gt_id, horizon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Generate predictions\n",
    "#\n",
    "# Get template file names\n",
    "forecast_template = get_forecast_filename(\n",
    "    model=output_model_name, submodel=submodel_name, \n",
    "    gt_id=gt_id, horizon=horizon, \n",
    "    target_date_str=\"{}\")\n",
    "det_forecast_templates = [\n",
    "    get_forecast_filename(\n",
    "        model=model_name, submodel=det_submodel_name, \n",
    "        gt_id=det_gt_id, horizon=horizon, \n",
    "        target_date_str=\"{}\")\n",
    "    for det_submodel_name in det_submodel_names]\n",
    "for target_date_obj in target_date_objs:\n",
    "    # Skip if forecast already produced for this target\n",
    "    target_date_str = datetime.strftime(target_date_obj, '%Y%m%d')\n",
    "    forecast_file = forecast_template.format(target_date_str)\n",
    "    if os.path.isfile(forecast_file):\n",
    "        printf(f\"\\nprior forecast exists for target={target_date_obj}\")\n",
    "        continue\n",
    "    \n",
    "    tic()\n",
    "    # Identify the target terciles for this month-day combo\n",
    "    target_terc = terc_data[(target_date_obj.month, target_date_obj.day)]\n",
    "    \n",
    "    # Compute fraction of deterministic submodel forecasts falling into \n",
    "    # the tercile bin\n",
    "    prob_pred = pd.Series(index=terc_data.index, data=0., dtype='float', name=\"pred\")\n",
    "    num_det_forecasts = 0\n",
    "    for det_forecast_template in det_forecast_templates:\n",
    "        # Load deterministic forecast\n",
    "        det_forecast_file = det_forecast_template.format(target_date_str)\n",
    "        if not os.path.isfile(det_forecast_file):\n",
    "            continue\n",
    "        det_pred = pd.read_hdf(det_forecast_file).loc[:,['lat','lon','pred']].set_index(['lat','lon']).squeeze()\n",
    "        # Skip if deterministic forecast contains nans\n",
    "        if det_pred.isnull().values.any():\n",
    "            printf(f\"\\n{det_forecast_file} contains nans; skipping\")\n",
    "            continue\n",
    "        num_det_forecasts += 1\n",
    "        if load_tercile == 1:\n",
    "            # Check if predictions belong to first tercile bin\n",
    "            prob_pred += (det_pred <= target_terc)\n",
    "        else:\n",
    "            # Check if predictions belong to third tercile bin\n",
    "            prob_pred += (det_pred > target_terc)\n",
    "    \n",
    "    if num_det_forecasts == 0:\n",
    "        printf(f\"\\nno deterministic forecasts for target={target_date_obj}; skipping\")\n",
    "        toc()\n",
    "        continue\n",
    "    if num_det_forecasts == 1:\n",
    "        printf(f\"\\nonly one deterministic forecast for target={target_date_obj}; skipping\")\n",
    "        toc()\n",
    "        continue        \n",
    "    printf(f\"\\nForming predictions for target={target_date_obj} based on {num_det_forecasts} forecasts\")\n",
    "    # Divide by the number of contributing forecasts\n",
    "    prob_pred /= num_det_forecasts\n",
    "\n",
    "    # Save prediction to file in standard format\n",
    "    prob_pred = prob_pred.reset_index()\n",
    "    # Add start date column after lat and lon\n",
    "    prob_pred.insert(2,'start_date',target_date_obj)\n",
    "    save_forecasts(prob_pred,\n",
    "        model=output_model_name, submodel=submodel_name, \n",
    "        gt_id=gt_id, horizon=horizon, \n",
    "        target_date_str=target_date_str)\n",
    "    toc()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
