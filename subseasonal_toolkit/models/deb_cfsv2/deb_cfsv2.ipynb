{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debiased CFSv2\n",
    "\n",
    "## Debiases CFSv2 ensemble forecast over specified range of years and leads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "from subseasonal_toolkit.utils.notebook_util import isnotebook\n",
    "if isnotebook():\n",
    "    # Autoreload packages that are modified\n",
    "    %load_ext autoreload\n",
    "    %autoreload 2\n",
    "else:\n",
    "    from argparse import ArgumentParser\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.spatial.distance import cdist, euclidean\n",
    "from datetime import datetime, timedelta\n",
    "from ttictoc import tic, toc\n",
    "from subseasonal_data.utils import get_measurement_variable\n",
    "from subseasonal_toolkit.utils.general_util import printf\n",
    "from subseasonal_toolkit.utils.experiments_util import get_first_year, get_forecast_delta\n",
    "from subseasonal_toolkit.utils.models_util import (get_submodel_name, start_logger, log_params, get_forecast_filename,\n",
    "                                                   save_forecasts)\n",
    "from subseasonal_toolkit.utils.eval_util import get_target_dates, mean_rmse_to_score, save_metric\n",
    "from sklearn.linear_model import *\n",
    "\n",
    "from subseasonal_data import data_loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Specify model parameters\n",
    "#\n",
    "model_name = \"deb_cfsv2\"\n",
    "if not isnotebook():\n",
    "    # If notebook run as a script, parse command-line arguments\n",
    "    parser = ArgumentParser()\n",
    "    parser.add_argument(\"pos_vars\",nargs=\"*\")  # gt_id and horizon                                                                                  \n",
    "    parser.add_argument('--target_dates', '-t', default=\"std_test\")\n",
    "    parser.add_argument('--first_year', '-fy', default=1999,\n",
    "                        help=\"first year (inclusive) to use for debiasing\")\n",
    "    parser.add_argument('--last_year', '-ly', default=2010,\n",
    "                        help=\"last year (inclusive) to use for debiasing\")\n",
    "    parser.add_argument('--first_lead', '-fl', default=0, \n",
    "                        help=\"first cfsv2 lead to average into forecast (0-29)\")\n",
    "    parser.add_argument('--last_lead', '-ll', default=29, \n",
    "                        help=\"last cfsv2 lead to average into forecast (0-29)\")\n",
    "    args, opt = parser.parse_known_args()\n",
    "    \n",
    "    # Assign variables                                                                                                                                     \n",
    "    gt_id = args.pos_vars[0] # \"contest_precip\" or \"contest_tmp2m\"                                                                            \n",
    "    horizon = args.pos_vars[1] # \"12w\", \"34w\", or \"56w\"                                                                                        \n",
    "    target_dates = args.target_dates\n",
    "    first_lead = int(args.first_lead)\n",
    "    last_lead = int(args.last_lead)\n",
    "    first_year = int(args.first_year)\n",
    "    last_year = int(args.last_year)\n",
    "else:\n",
    "    # Otherwise, specify arguments interactively \n",
    "    gt_id = \"us_tmp2m_1.5x1.5\"\n",
    "    horizon = \"34w\"\n",
    "    target_dates = \"std_ecmwf\"        \n",
    "    first_year = 1999\n",
    "    last_year = 2010\n",
    "    if horizon == \"34w\":\n",
    "        first_lead = 15\n",
    "        last_lead = 15\n",
    "    elif horizon == \"56w\":\n",
    "        first_lead = 29\n",
    "        last_lead = 29\n",
    "\n",
    "#\n",
    "# Choose regression parameters\n",
    "#\n",
    "# Record standard settings of these parameters\n",
    "if gt_id.endswith(\"1.5x1.5\"):\n",
    "    prefix = \"iri_cfsv2\"\n",
    "else:\n",
    "    prefix = \"subx_cfsv2\" \n",
    "if \"tmp2m\" in gt_id:\n",
    "    base_col = prefix+'_tmp2m'\n",
    "elif \"precip\" in gt_id:\n",
    "    base_col = prefix+'_precip'\n",
    "\n",
    "#\n",
    "# Process model parameters\n",
    "#\n",
    "\n",
    "# Get list of target date objects\n",
    "target_date_objs = pd.Series(get_target_dates(date_str=target_dates, horizon=horizon))\n",
    "\n",
    "# Identify measurement variable name\n",
    "measurement_variable = get_measurement_variable(gt_id) # 'tmp2m' or 'precip'\n",
    "\n",
    "# Column name for ground truth\n",
    "gt_col = measurement_variable\n",
    "\n",
    "LAST_SAVE_YEAR = get_first_year(prefix) # Don't save forecasts for years earlier than LAST_SAVE_YEAR\n",
    "\n",
    "# Record model and submodel names\n",
    "submodel_name = get_submodel_name(\n",
    "    model_name, \n",
    "    first_year=first_year, last_year=last_year,\n",
    "    first_lead=first_lead, last_lead=last_lead)\n",
    "\n",
    "if not isnotebook():\n",
    "    # Save output to log file\n",
    "    logger = start_logger(model=model_name,submodel=submodel_name,gt_id=gt_id,\n",
    "                          horizon=horizon,target_dates=target_dates)\n",
    "    # Store parameter values in log                                                                                                                        \n",
    "    params_names = ['gt_id', 'horizon', 'target_dates',\n",
    "                    'first_year', 'last_year', \n",
    "                    'first_lead', 'last_lead',\n",
    "                    'base_col'\n",
    "                   ]\n",
    "    params_values = [eval(param) for param in params_names]\n",
    "    log_params(params_names, params_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and process CFSv2 data\n",
    "printf(\"Loading cfsv2 data and averaging leads\")\n",
    "# Choose data shift based on horizon\n",
    "base_shift = get_forecast_delta(horizon) \n",
    "\n",
    "tic()\n",
    "mask = None\n",
    "if gt_id.startswith(\"us_\"):\n",
    "    suffix = \"-us\"  \n",
    "else:\n",
    "    suffix = \"\"\n",
    "if gt_id.endswith(\"1.5x1.5\"):\n",
    "    suffix += \"1_5\"\n",
    "else:\n",
    "    mask = data_loaders.get_us_mask()\n",
    "\n",
    "data = data_loaders.get_forecast(prefix+\"-\"+measurement_variable+suffix, \n",
    "                                 mask_df=mask,\n",
    "                                 shift=base_shift)\n",
    "cols = [prefix+\"_\"+gt_id.split(\"_\")[1]+\"-{}.5d_shift{}\".format(col,base_shift) \n",
    "        for col in range(first_lead, last_lead+1)]\n",
    "data[base_col] = data[cols].mean(axis=1)\n",
    "toc()\n",
    "\n",
    "printf('Pivoting dataframe to have one row per start_date')\n",
    "tic()\n",
    "data = data[['lat','lon','start_date',base_col]].set_index(['lat','lon','start_date']).unstack(['lat','lon'])\n",
    "toc()\n",
    "\n",
    "# Load ground truth\n",
    "tic()\n",
    "gt = data_loaders.get_ground_truth(gt_id).loc[:,['lat','lon','start_date',gt_col]]\n",
    "toc()\n",
    "printf('Pivoting ground truth to have one row per start_date')\n",
    "tic()\n",
    "gt = gt.loc[gt.start_date.isin(data.index),['lat','lon','start_date',gt_col]].set_index(['lat','lon','start_date']).unstack(['lat','lon'])\n",
    "toc()\n",
    "printf(\"Merging ground truth\")\n",
    "tic()\n",
    "data = data.join(gt, how=\"left\") \n",
    "del gt\n",
    "toc()\n",
    "\n",
    "# Identify the month-day combination for each date treating 2/29 as 2/28\n",
    "monthdays = pd.Series([(d.month,d.day) if d.month != 2 or d.day != 29 \n",
    "                      else (2,28) for d in data.index],index=data.index)\n",
    "\n",
    "# Compute debiasing correction\n",
    "printf('Compute debiasing correction (ground-truth - base prediction) by month-day combination')\n",
    "tic()\n",
    "debias = (data[gt_col] - data[base_col])\n",
    "debias = debias[(debias.index >= str(first_year)) & (debias.index <= str(last_year))]\n",
    "debias = debias.groupby(by=monthdays[debias.index]).mean()\n",
    "toc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions for each target date\n",
    "printf('Creating dataframe to store performance')\n",
    "tic()\n",
    "rmses = pd.Series(index=target_date_objs, dtype=np.float64)\n",
    "toc()\n",
    "printf('Forming debiased predictions for target dates')\n",
    "tic()\n",
    "# Form predictions for target dates in data matrix\n",
    "valid_targets = data.index.intersection(target_date_objs)\n",
    "target_monthdays = monthdays.loc[valid_targets]\n",
    "preds = data.loc[valid_targets, base_col] + debias.loc[target_monthdays].values\n",
    "preds.index.name = \"start_date\"\n",
    "# Order valid targets by day of week\n",
    "valid_targets = valid_targets[valid_targets.weekday.argsort(kind='stable')]\n",
    "toc()\n",
    "for target_date_obj in valid_targets:\n",
    "    # Skip if forecast already produced for this target\n",
    "    target_date_str = datetime.strftime(target_date_obj, '%Y%m%d')\n",
    "    forecast_file = get_forecast_filename(\n",
    "        model=model_name, submodel=submodel_name, \n",
    "        gt_id=gt_id, horizon=horizon, \n",
    "        target_date_str=target_date_str)\n",
    "    if os.path.isfile(forecast_file):\n",
    "        printf(f\"prior forecast exists for target={target_date_obj}\")\n",
    "        pred = pd.read_hdf(forecast_file).set_index(['lat','lon']).pred\n",
    "    else:\n",
    "        printf(f'Processing {model_name} forecast for {target_date_obj}')\n",
    "        tic()\n",
    "        # Add correction to base prediction\n",
    "        pred = preds.loc[target_date_obj,:]\n",
    "        # Save prediction to file in standard format\n",
    "        if target_date_obj.year >= LAST_SAVE_YEAR:\n",
    "            save_forecasts(\n",
    "                preds.loc[[target_date_obj],:].unstack().rename(\"pred\").reset_index(),\n",
    "                model=model_name, submodel=submodel_name, \n",
    "                gt_id=gt_id, horizon=horizon, \n",
    "                target_date_str=target_date_str)\n",
    "        toc()\n",
    "    # Evaluate and store error if we have ground truth data\n",
    "    tic()\n",
    "    if target_date_obj in data.index:\n",
    "        rmse = np.sqrt(np.square(pred - data.loc[target_date_obj,gt_col]).mean())\n",
    "        rmses.loc[target_date_obj] = rmse\n",
    "        printf(\"-rmse: {}, score: {}\".format(rmse, mean_rmse_to_score(rmse)))\n",
    "        mean_rmse = rmses.mean()\n",
    "        printf(\"-mean rmse: {}, running score: {}\".format(mean_rmse, mean_rmse_to_score(mean_rmse)))\n",
    "    toc()\n",
    "\n",
    "printf(\"Save rmses in standard format\")\n",
    "rmses = rmses.sort_index().reset_index()\n",
    "rmses.columns = ['start_date','rmse']\n",
    "save_metric(rmses, model=model_name, submodel=submodel_name, gt_id=gt_id, horizon=horizon, target_dates=target_dates, metric=\"rmse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
