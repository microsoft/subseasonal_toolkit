{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ECMWF++\n",
    "\n",
    "Ensembling and debiasing of ECMWF forecasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "# Ensure notebook is being run from base repository directory\n",
    "import os, sys\n",
    "try:\n",
    "    os.chdir(\"/home/{}/forecast_rodeo_ii\".format(os.environ[\"USER\"]))\n",
    "except Exception as err:\n",
    "    print(f\"Warning: unable to change directory; {repr(err)}\")\n",
    "from subseasonal_toolkit.utils.notebook_util import isnotebook\n",
    "if isnotebook():\n",
    "    # Autoreload packages that are modified\n",
    "    %load_ext autoreload\n",
    "    %autoreload 2\n",
    "else:\n",
    "    from argparse import ArgumentParser\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "from subseasonal_data.utils import get_measurement_variable\n",
    "from subseasonal_toolkit.utils.general_util import printf, tic, toc\n",
    "from subseasonal_toolkit.utils.experiments_util import (get_first_year, get_start_delta,\n",
    "                                                        get_forecast_delta)\n",
    "from subseasonal_toolkit.utils.models_util import (get_submodel_name, start_logger, log_params, get_forecast_filename,\n",
    "                                                   save_forecasts)\n",
    "from subseasonal_toolkit.utils.eval_util import get_target_dates, mean_rmse_to_score, save_metric\n",
    "from subseasonal_toolkit.models.deb_ecmwf.ecmwf_utils import geometric_median, ssm\n",
    "\n",
    "from subseasonal_data import data_loaders\n",
    "\n",
    "import pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Specify model parameters\n",
    "#\n",
    "model_name = \"ecmwfpp\"\n",
    "if not isnotebook():\n",
    "    # If notebook run as a script, parse command-line arguments\n",
    "    parser = ArgumentParser()\n",
    "    parser.add_argument(\"pos_vars\",nargs=\"*\")  # gt_id and horizon \n",
    "    parser.add_argument('--target_dates', '-t', default=\"std_test\")\n",
    "    # Fit intercept parameter if and only if this flag is specified\n",
    "    parser.add_argument('--fit_intercept', '-i', default=\"False\",\n",
    "                        choices=['True', 'False'],\n",
    "                        help=\"Fit intercept parameter if \\\"True\\\"; do not if \\\"False\\\"\")    \n",
    "    parser.add_argument('--train_years', '-y', default=20,\n",
    "                       help=\"Number of years to use in debiasing (integer)\")     \n",
    "    parser.add_argument('--margin_in_days', '-m', default=\"None\",\n",
    "                       help=\"number of month-day combinations on either side of the target combination \"\n",
    "                            \"to include when training; set to 0 include only target month-day combo; \"\n",
    "                            \"set to None to include entire year\")    \n",
    "    parser.add_argument('--first_day', '-fd', default=1,\n",
    "                        help=\"first available daily cfsv2 forecast (1 or greater) to average\")\n",
    "    parser.add_argument('--last_day', '-ld', default=1,\n",
    "                        help=\"last available daily cfsv2 forecast (first_day or greater) to average\")    \n",
    "    parser.add_argument('--loss', '-l', default=\"mse\", \n",
    "                        help=\"loss function: mse, rmse, skill, or ssm\")\n",
    "    parser.add_argument('--first_lead', '-fl', default=0, \n",
    "                        help=\"first ecmwf lead to average into forecast (0-29)\")\n",
    "    parser.add_argument('--last_lead', '-ll', default=29, \n",
    "                        help=\"last ecmwf lead to average into forecast (0-29)\")\n",
    "    parser.add_argument('--forecast_with', '-fw', default=\"c\", \n",
    "                        help=\"Generate forecast using the control (c), \"\n",
    "                        \"average perturbed (p), single perturbed (p1, ..., p50), \"\n",
    "                        \"or perturbed-control ensemble (p+c) ECMWF forecast.\")\n",
    "    parser.add_argument('--debias_with', '-dw', default=\"c\", \n",
    "                        help=\"Debias using the control (c), average perturbed (p), \"\n",
    "                        \"or perturbed-control ensemble (p+c) ECMWF reforecast.\")      \n",
    "    \n",
    "    args, opt = parser.parse_known_args()\n",
    "    \n",
    "    # Assign variables\n",
    "    gt_id = args.pos_vars[0] # \"contest_precip\" or \"contest_tmp2m\"\n",
    "    horizon = args.pos_vars[1] # \"12w\", \"34w\", or \"56w\"\n",
    "    target_dates = args.target_dates\n",
    "    fit_intercept = args.fit_intercept   \n",
    "    if fit_intercept == \"False\":\n",
    "        fit_intercept = False\n",
    "    elif fit_intercept == \"True\":\n",
    "        fit_intercept = True\n",
    "    else:\n",
    "        raise ValueError(f\"unrecognized value {fit_intercept} for fit_intercept\")    \n",
    "    train_years = args.train_years\n",
    "    if train_years != \"all\":\n",
    "        train_years = int(train_years)\n",
    "    else:\n",
    "        train_yaers = np.inf\n",
    "    if args.margin_in_days == \"None\":\n",
    "        margin_in_days = None\n",
    "    else:\n",
    "        margin_in_days = int(args.margin_in_days)        \n",
    "    first_day = int(args.first_day)\n",
    "    last_day = int(args.last_day)        \n",
    "    loss = args.loss\n",
    "    first_lead = int(args.first_lead)\n",
    "    last_lead = int(args.last_lead)\n",
    "    debias_with = args.debias_with\n",
    "    forecast_with = args.forecast_with \n",
    "else:\n",
    "    # Otherwise, specify arguments interactively \n",
    "    gt_id = \"us_precip_1.5x1.5\"#\"global_precip_p1_1.5x1.5\" # us_precip_1.5x1.5, us_tmp2m_1.5x1.5, must use 1.5x1.5 forecasts for ecmwf\n",
    "    horizon = \"12w\"\n",
    "    target_dates = \"std_paper_eval\"\n",
    "    fit_intercept = True    \n",
    "    loss = \"mse\"\n",
    "    train_years = 20\n",
    "    margin_in_days = 28    \n",
    "    if \"tmp2m\" in gt_id and (horizon == \"12w\"):\n",
    "        first_day = 1\n",
    "        last_day = 1        \n",
    "        first_lead = 1\n",
    "        last_lead = 1\n",
    "    elif \"precip\" in gt_id and (horizon == \"12w\"):\n",
    "        first_day = 1\n",
    "        last_day = 1        \n",
    "        first_lead = 1\n",
    "        last_lead = 1\n",
    "    elif \"tmp2m\" in gt_id and (horizon == \"34w\"):\n",
    "        first_day = 1\n",
    "        last_day = 7        \n",
    "        first_lead = 15\n",
    "        last_lead = 15\n",
    "    elif \"precip\" in gt_id and (horizon == \"34w\"):\n",
    "        first_day = 1\n",
    "        last_day = 35        \n",
    "        first_lead = 15\n",
    "        last_lead = 15\n",
    "    elif \"tmp2m\" in gt_id and (horizon == \"56w\"):\n",
    "        first_day = 1\n",
    "        last_day = 14         \n",
    "        first_lead = 29\n",
    "        last_lead = 29\n",
    "    elif \"precip\" in gt_id and (horizon == \"56w\"):\n",
    "        first_day = 1\n",
    "        last_day = 21        \n",
    "        first_lead = 29\n",
    "        last_lead = 29\n",
    "    debias_with = \"p+c\"\n",
    "    forecast_with = \"p+c\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "Choose regression parameters and record standard settings\n",
    "of these parameters\n",
    "\"\"\"\n",
    "x_cols = ['zeros']\n",
    "if \"tmp2m\" in gt_id:\n",
    "    base_col = 'ecmwf_tmp2m'\n",
    "elif \"precip\" in gt_id:\n",
    "    base_col = 'ecmwf_precip' \n",
    "group_by_cols = ['lat', 'lon']    \n",
    "\n",
    "\"\"\" \n",
    "Process model parameters\"\"\"\n",
    "\n",
    "# Get list of target date objects\n",
    "target_date_objs = pd.Series(get_target_dates(\n",
    "    date_str=target_dates, horizon=horizon))\n",
    "\n",
    "# Identify measurement variable name\n",
    "measurement_variable = get_measurement_variable(gt_id) # 'tmp2m' or 'precip'\n",
    "\n",
    "# Column names for gt_col, clim_col and anom_col \n",
    "gt_col = measurement_variable\n",
    "clim_col = measurement_variable+\"_clim\"\n",
    "anom_col = get_measurement_variable(gt_id)+\"_anom\" # 'tmp2m_anom' or 'precip_anom'\n",
    "\n",
    "# Store delta between target date and forecast issuance date\n",
    "start_delta =  timedelta(days=get_start_delta(horizon, gt_id))\n",
    "base_shift_delta = timedelta(days=get_forecast_delta(horizon))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Don't save forecasts for years earlier than LAST_SAVE_YEAR\n",
    "LAST_SAVE_YEAR = get_first_year(model_name) \n",
    "\n",
    "# Record model and submodel names\n",
    "submodel_name = get_submodel_name(\n",
    "    model_name, fit_intercept=fit_intercept,\n",
    "    train_years=train_years, margin_in_days=margin_in_days,\n",
    "    first_day=first_day, last_day=last_day, loss=loss, \n",
    "    first_lead=first_lead, last_lead=last_lead,\n",
    "    forecast_with=forecast_with, debias_with=debias_with)\n",
    "print(submodel_name)\n",
    "\n",
    "if not isnotebook():\n",
    "    # Save output to log file\n",
    "    logger = start_logger(model=model_name,submodel=submodel_name, gt_id=gt_id,\n",
    "                          horizon=horizon, target_dates=target_dates)\n",
    "    \n",
    "    # Store parameter values in log                                                                                                                        \n",
    "    params_names = ['gt_id', 'horizon', 'target_dates',\n",
    "                    'fit_intercept', 'train_years', 'margin_in_days',\n",
    "                    'first_day', 'last_day', 'loss', \n",
    "                    'first_lead', 'last_lead', 'forecast_with', 'debias_with',\n",
    "                    'base_col', 'x_cols', 'group_by_cols']    \n",
    "    params_values = [eval(param) for param in params_names]\n",
    "    log_params(params_names, params_values)\n",
    "    \n",
    "# Select estimator based on loss\n",
    "if loss == \"rmse\":\n",
    "    estimator = geometric_median \n",
    "elif loss == \"ssm\":\n",
    "    estimator = ssm\n",
    "else: \n",
    "    estimator = np.mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and process data\n",
    "printf(\"Loading ecmwf data\")\n",
    "# Choose data shift based on horizon and first day to be averaged\n",
    "base_shift = get_forecast_delta(horizon)\n",
    "\n",
    "if \"1.5x1.5\" in gt_id:\n",
    "    # Get the mask\n",
    "    if gt_id.startswith('us_'):\n",
    "        mask_df = data_loaders.get_us_mask(fname=\"us_1_5_mask.nc\", sync=False)\n",
    "        # Create list of forecast and reforecast data to load\n",
    "        load_names = []\n",
    "        if forecast_with == \"p+c\":\n",
    "            forecast_prefix = \"ef\"\n",
    "        else:\n",
    "            # Construct forecast name prefix with format cf, pf, pf1, ..., pf50\n",
    "            forecast_prefix = forecast_with[:1]+\"f\"+forecast_with[1:]\n",
    "        load_names.append(forecast_prefix+\"-forecast\")\n",
    "        if debias_with == \"p+c\":\n",
    "            debias_prefix = \"ef\"\n",
    "        else:\n",
    "            # Construct forecast name prefix with format cf, pf\n",
    "            debias_prefix = debias_with[:1]+\"f\"+debias_with[1:]\n",
    "        load_names.append(debias_prefix+\"-reforecast\")            \n",
    "    elif gt_id.startswith('global_'):\n",
    "        # Global data\n",
    "        mask_df = None    \n",
    "        load_names = [\"forecast\", \"reforecast\"]\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown gt_id {gt_id}\")\n",
    "    \n",
    "    \"\"\"Load forecast and reforecast data.\"\"\"     \n",
    "    cols = [\"iri_ecmwf_\"+gt_id.split(\"_\")[1]+\"-{}.5d_shift{}\".format(col, base_shift) \n",
    "            for col in range(first_lead, last_lead+1)]  \n",
    "    \n",
    "    load_data = {}\n",
    "    for l in load_names:\n",
    "        print(\"Loading data.\")\n",
    "        load_data[l] = data_loaders.get_forecast(\n",
    "            f\"ecmwf-{measurement_variable}-{gt_id.split('_')[0]}1_5-{l}\", \n",
    "            mask_df=mask_df,\n",
    "            shift=base_shift,\n",
    "            sync=False)  \n",
    "        \n",
    "        # Undo-shifting of model_issuance_date so that it matches the start date\n",
    "        if \"reforecast\" in l:\n",
    "            try:\n",
    "                load_data[l]['model_issuance_date'] = load_data[l][f'model_issuance_date_shift{base_shift}'] \\\n",
    "                    + timedelta(days=base_shift)        \n",
    "            except:\n",
    "                pdb.set_trace()\n",
    "                load_data[l] = data_loaders.get_forecast(\n",
    "                    f\"ecmwf-{measurement_variable}-{gt_id.split('_')[0]}1_5-{l}\", \n",
    "                    mask_df=mask_df,\n",
    "                    shift=base_shift,\n",
    "                    sync=False)                  \n",
    "\n",
    "        printf(\"Averaging leads for forecast and debias data.\")\n",
    "        \n",
    "        load_data[l][base_col] = load_data[l][cols].mean(axis=1)\n",
    "\n",
    "        printf('Pivoting dataframe to have one row per start_date')\n",
    "        if \"reforecast\" in l:\n",
    "            load_data[l] = load_data[l][\n",
    "                ['lat','lon','start_date', 'model_issuance_date', base_col]].set_index(\n",
    "                ['lat','lon','start_date', 'model_issuance_date']).unstack(['lat','lon'])            \n",
    "        else:\n",
    "            load_data[l] = load_data[l][['lat','lon','start_date', base_col]].set_index(\n",
    "                ['lat','lon','start_date']).unstack(['lat','lon'])     \n",
    "            \n",
    "\n",
    "        printf(f\"Computing rolling mean over days {first_day}-{last_day}\")\n",
    "        days = last_day - first_day + 1\n",
    "        if \"reforecast\" in l:\n",
    "            load_data[l] = load_data[l].rolling(\n",
    "                f\"{days}d\", on=load_data[l].index.get_level_values(\"start_date\")\n",
    "            ).mean().dropna(how='any')\n",
    "        else:\n",
    "            load_data[l] = load_data[l].rolling(f\"{days}d\").mean().dropna(how='any')\n",
    "else:\n",
    "    raise ValueError(\"ECMWF model only configured for 1.5 gt_ids for now.\")            \n",
    "\n",
    "if gt_id.startswith('us_'):\n",
    "    # forecast_prefix in {\"ef\",\"cf\",\"pf\",\"pf1\",...,\"pf50\"}\n",
    "    forecast_data = load_data[f\"{forecast_prefix}-forecast\"]\n",
    "    # debias_prefix in {\"ef\",\"cf\",\"pf\"}\n",
    "    debias_data = load_data[f\"{debias_prefix}-reforecast\"]\n",
    "else:\n",
    "    forecast_data = load_data[\"forecast\"]\n",
    "    debias_data = load_data[\"reforecast\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Load and merge ground truth \n",
    "\"\"\"\n",
    "printf('Pivoting ground truth to have one row per start_date')\n",
    "gt = data_loaders.get_ground_truth(gt_id)\\\n",
    "        .loc[:,['lat','lon','start_date', gt_col]]\n",
    "\n",
    "# Need gt for both the debias and the forecast dates\n",
    "gt = gt.loc[gt.start_date.isin(\n",
    "                debias_data.index.get_level_values(\"start_date\") |\n",
    "                forecast_data.index.get_level_values(\"start_date\")),\n",
    "            ['lat','lon','start_date', gt_col]].set_index(\n",
    "            ['lat','lon','start_date']).unstack(['lat','lon'])\n",
    "\n",
    "printf(\"Merging ground truth\")\n",
    "debias_data = debias_data.join(gt, how=\"left\", on=\"start_date\") \n",
    "forecast_data = forecast_data.join(gt, how=\"left\", on=\"start_date\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The first target date for which an ECMWF forecast exists\n",
    "# 1. FIRST_AVAILABLE_FORECAST_TARGET_DATE := (need to look this up; it's the first target date \n",
    "# for which an ECMWF forecast exists)\n",
    "FIRST_FORECAST_TARGET_DATE = datetime.strptime(\"2015-05-14\", \"%Y-%m-%d\")\n",
    "\n",
    "# The first date in \"std_ecmwf\" target dates\n",
    "# 2. FIRST_EVALUATION_TARGET_DATE := (this is the first date in our set of ABC-paper evaluation dates for ECMWF, \n",
    "# something like 2016-01-01)\n",
    "FIRST_EVALUATION_TARGET_DATE = sorted(get_target_dates(\"std_paper_ecmwf\"))[0] \n",
    "\n",
    "\n",
    "#2'. FIRST_TUNING_TARGET_DATE := (this is the first date used for tuning with num_years=3 and margin=None)\n",
    "FIRST_TUNING_TARGET_DATE = datetime.strptime(f\"{FIRST_EVALUATION_TARGET_DATE.year-3}-01-01\", \"%Y-%m-%d\")\n",
    "\n",
    "# 3. LAST_REFORECAST_ISSUANCE_DATE := the issuance date associated with FIRST_EVALUATION_TARGET_DATE. \n",
    "# [Translation: this is FIRST_EVALUATION_TARGET_DATE minus the offset depending on the horizon]\n",
    "LAST_REFORECAST_ISSUANCE_DATE = FIRST_EVALUATION_TARGET_DATE - base_shift_delta\n",
    "\n",
    "# print(f\"FIRST_FORECAST_TARGET_DATE is: {FIRST_FORECAST_TARGET_DATE}\")\n",
    "# print(f\"FIRST_EVALUATION_TARGET_DATE is: {FIRST_EVALUATION_TARGET_DATE}\")\n",
    "# print(f\"FIRST_TUNING_TARGET_DATE is: {FIRST_TUNING_TARGET_DATE}\")\n",
    "# print(f\"LAST_REFORECAST_ISSUANCE_DATE is: {LAST_REFORECAST_ISSUANCE_DATE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. If target date < FIRST_FORECAST_TARGET_DATE:\n",
    "# 5.a. Ignore any reforecast data that was produced after LAST_REFORECAST_ISSUANCE_DATE\n",
    "#Get debias data\n",
    "debias_data_refasf = debias_data[debias_data.index.get_level_values(\"model_issuance_date\")<LAST_REFORECAST_ISSUANCE_DATE]\n",
    "\n",
    "# 5. If target date < FIRST_FORECAST_TARGET_DATE:\n",
    "# 5.b. Base forecast = ECMWF reforecast (if one exists, otherwise skip this date)\n",
    "forecast_data_refasf = debias_data_refasf.reset_index().drop(\"model_issuance_date\", axis=1, level=0).set_index(\"start_date\")\n",
    "forecast_data_refasf = forecast_data_refasf[forecast_data_refasf.index < FIRST_EVALUATION_TARGET_DATE]\n",
    "data = forecast_data_refasf.sort_index()\n",
    "\n",
    "# 5.c. Debiasing correction based on associated ECMWF reforecasts with start dates prior to the reforecast target date\n",
    "bias_refasf = (debias_data_refasf[gt_col] - debias_data_refasf[base_col])\n",
    "bias_refasf = bias_refasf.reset_index().drop(\"model_issuance_date\", axis=1, level=0).set_index(\"start_date\")\n",
    "target = bias_refasf.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions for each target date\n",
    "printf('Creating dataframes to store performance and date-based covariates')\n",
    "tic()\n",
    "X = pd.DataFrame(index=target.index, columns = [\"delta\", \"dividend\", \"remainder\"], \n",
    "                 dtype=np.float64)\n",
    "toc()\n",
    "printf('Initializing target date predictions to base column')\n",
    "tic()\n",
    "# Only form predictions for target dates in data matrix\n",
    "valid_targets_refasf = data.index.intersection(target_date_objs)\n",
    "preds_refasf = data.loc[valid_targets_refasf, base_col]\n",
    "preds_refasf.index.name = \"start_date\"\n",
    "# # Order valid targets by day of week\n",
    "# valid_targets_refasf = sorted(valid_targets_refasf[valid_targets_refasf.weekday.argsort(kind='stable')])\n",
    "toc()\n",
    "days_per_year = 365.242199"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute debiasing correction\n",
    "printf('Compute debiasing correction (ground-truth - base prediction) by month-day combination')\n",
    "\n",
    "# Compute bias\n",
    "bias = (debias_data[gt_col] - debias_data[base_col])\n",
    "\n",
    "# Initialize bias per start_date dataframe in forecast dir\n",
    "avg_bias = pd.DataFrame(columns=bias.columns, \n",
    "                        index=bias.index.get_level_values(\n",
    "                            'model_issuance_date').unique().sort_values())\n",
    "\n",
    "for (date, df) in bias.groupby(by=\"model_issuance_date\"):\n",
    "    # Get all forecasts within +/- days of the day/month of the current forecast\n",
    "    # and within train years of the target year\n",
    "    last_train_date = date - start_delta\n",
    "    if margin_in_days is None:\n",
    "        debias = bias[\n",
    "                (bias.index.get_level_values(\"start_date\") >= str(date.year - train_years)) &        \n",
    "                (bias.index.get_level_values(\"start_date\") <= last_train_date)]\n",
    "    else:\n",
    "        debias = bias[\n",
    "                (bias.index.get_level_values(\"start_date\") >= str(date.year - train_years)) &        \n",
    "                (bias.index.get_level_values(\"start_date\") <= last_train_date) &        \n",
    "                (bias.index.get_level_values(\"model_issuance_date\") <= date + timedelta(days=margin_in_days)) &\n",
    "                (bias.index.get_level_values(\"model_issuance_date\") >= date - timedelta(days=margin_in_days))]\n",
    "    \n",
    "    avg_bias.loc[date] = estimator(debias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions for each target date\n",
    "printf('Creating dataframe to store performance')\n",
    "rmses = pd.Series(index=target_date_objs, dtype=np.float64)\n",
    "\n",
    "printf('Forming debiased predictions for target dates')\n",
    "# Form predictions for target dates in data matrix\n",
    "valid_targets = forecast_data.index.intersection(target_date_objs) # intersect with forecast data\n",
    "valid_targets = avg_bias.index.intersection(valid_targets) # intersect with debiasing data\n",
    "\n",
    "if fit_intercept:\n",
    "    # Debias the data\n",
    "    preds = forecast_data.loc[valid_targets, base_col] + avg_bias.loc[valid_targets]\n",
    "else:\n",
    "    # Do nothing \n",
    "    preds = forecast_data.loc[valid_targets, base_col]\n",
    "preds.index.name = \"start_date\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_targets = valid_targets.union(valid_targets_refasf)\n",
    "for target_date_obj in valid_targets:\n",
    "    # Skip if forecast already produced for this target\n",
    "    target_date_str = datetime.strftime(target_date_obj, '%Y%m%d')\n",
    "    forecast_file = get_forecast_filename(\n",
    "        model=model_name, submodel=submodel_name, \n",
    "        gt_id=gt_id, horizon=horizon, \n",
    "        target_date_str=target_date_str)\n",
    "    if target_date_obj <= FIRST_TUNING_TARGET_DATE:\n",
    "        continue\n",
    "    elif os.path.isfile(forecast_file):\n",
    "        printf(f\"\\nprior forecast exists for target={target_date_obj}\")\n",
    "        pred = pd.read_hdf(forecast_file).set_index(['lat','lon']).pred\n",
    "    elif target_date_obj >= FIRST_FORECAST_TARGET_DATE:\n",
    "        printf(f'\\nProcessing {model_name} forecast for {target_date_obj}')\n",
    "        tic()\n",
    "        # Get prediction \n",
    "        pred = preds.loc[target_date_obj,:]\n",
    "        # Save prediction to file in standard format\n",
    "#          if target_date_obj.year >= LAST_SAVE_YEAR:\n",
    "        save_forecasts(\n",
    "            preds.loc[[target_date_obj],:].unstack().rename(\"pred\").reset_index(),\n",
    "            model=model_name, submodel=submodel_name, \n",
    "            gt_id=gt_id, horizon=horizon, \n",
    "            target_date_str=target_date_str)\n",
    "        toc()\n",
    "    else:\n",
    "        printf(f'\\nProcessing {model_name} forecast for {target_date_obj}')\n",
    "        tic()\n",
    "#         printf(f\"Preparing covariates for {target_date_str}\")\n",
    "        # Compute days from target date\n",
    "        X['delta'] = (target_date_obj - target.index).days\n",
    "        # Extract the dividend and remainder when delta is divided by the number of days per year\n",
    "        # The dividend is analogous to the year\n",
    "        # (Negative values will ultimately be excluded)\n",
    "        X['dividend'] = np.floor(X.delta / days_per_year)\n",
    "        # The remainder is analogous to the day of the year\n",
    "        X['remainder'] = np.floor(X.delta % days_per_year)\n",
    "        # Find the last observable training date for this target\n",
    "        last_train_date = target_date_obj - start_delta\n",
    "        # Restrict data based on training date, dividend, and remainder\n",
    "        indic = (X.index <= last_train_date)\n",
    "        if margin_in_days is not None:\n",
    "            indic &= ((X.remainder <= margin_in_days) | (X.remainder >= 365-margin_in_days))\n",
    "        if train_years != \"all\":\n",
    "            indic = indic & (X.dividend < train_years)\n",
    "        toc()\n",
    "#         printf(f'Fitting {model_name} model with loss {loss} for {target_date_obj}')\n",
    "        tic()\n",
    "        if fit_intercept and not indic.any():\n",
    "            printf(f'-Warning: no training data for {target_date_str}; using base prediction')\n",
    "            # Do not adjust base prediction\n",
    "            pred = 0\n",
    "        elif fit_intercept:\n",
    "            # Add learned prediction to base prediction\n",
    "            pred = estimator(target.loc[indic,:])\n",
    "            preds_refasf.loc[target_date_obj,:] += pred\n",
    "        else:\n",
    "            # Do not adjust base prediction\n",
    "            pred = 0\n",
    "        # Save prediction to file in standard format\n",
    "#         if target_date_obj.year >= LAST_SAVE_YEAR:\n",
    "        save_forecasts(\n",
    "            preds_refasf.loc[[target_date_obj],:].unstack().rename(\"pred\").reset_index(),\n",
    "            model=model_name, submodel=submodel_name, \n",
    "            gt_id=gt_id, horizon=horizon, \n",
    "            target_date_str=target_date_str)\n",
    "        toc()\n",
    "    # Evaluate and store error if we have ground truth data\n",
    "    tic()\n",
    "    if target_date_obj in forecast_data.index:\n",
    "        rmse = np.sqrt(np.square(pred - forecast_data.loc[target_date_obj, gt_col]).mean())\n",
    "        rmses.loc[target_date_obj] = rmse\n",
    "        printf(\"-rmse: {}, score: {}\".format(rmse, mean_rmse_to_score(rmse)))\n",
    "        mean_rmse = rmses.mean()\n",
    "        printf(\"-mean rmse: {}, running score: {}\".format(mean_rmse, mean_rmse_to_score(mean_rmse)))\n",
    "    elif target_date_obj in target.index:\n",
    "        rmse = np.sqrt(np.square(pred - target.loc[target_date_obj,:]).mean())\n",
    "        rmses.loc[target_date_obj] = rmse\n",
    "        print(\"-rmse: {}, score: {}\".format(rmse, mean_rmse_to_score(rmse)))\n",
    "        mean_rmse = rmses.mean()\n",
    "        print(\"-mean rmse: {}, running score: {}\".format(mean_rmse, mean_rmse_to_score(mean_rmse)))\n",
    "    toc()\n",
    "\n",
    "printf(\"Save rmses in standard format\")\n",
    "rmses = rmses.sort_index().reset_index()\n",
    "rmses.columns = ['start_date','rmse']\n",
    "save_metric(rmses, model=model_name, submodel=submodel_name, \n",
    "            gt_id=gt_id, horizon=horizon, target_dates=target_dates, \n",
    "            metric=\"rmse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
