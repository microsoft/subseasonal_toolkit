{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model tuner\n",
    "\n",
    "### Selects a best sub-model of a model for each target date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure notebook is being run from base repository directory\n",
    "import os, sys\n",
    "from subseasonal_toolkit.utils.notebook_util import isnotebook\n",
    "if isnotebook():\n",
    "    # Autoreload packages that are modified\n",
    "    %load_ext autoreload\n",
    "    %autoreload 2\n",
    "else:\n",
    "    from argparse import ArgumentParser\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import shutil\n",
    "from datetime import datetime, timedelta\n",
    "from filelock import FileLock\n",
    "from pkg_resources import resource_filename\n",
    "from ttictoc import tic, toc\n",
    "from subseasonal_data.utils import get_measurement_variable\n",
    "from subseasonal_toolkit.utils.general_util import printf, make_directories, symlink\n",
    "from subseasonal_toolkit.utils.experiments_util import get_first_year, get_start_delta\n",
    "from subseasonal_toolkit.utils.models_util import (get_submodel_name, start_logger, log_params, get_forecast_filename,\n",
    "                                                   save_forecasts)\n",
    "from subseasonal_toolkit.utils.eval_util import get_target_dates, mean_rmse_to_score\n",
    "from subseasonal_toolkit.models.tuner.util import *\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "from subseasonal_data import data_loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Specify model parameters\n",
    "#\n",
    "if not isnotebook():\n",
    "    # If notebook run as a script, parse command-line arguments\n",
    "    parser = ArgumentParser()\n",
    "    parser.add_argument(\"pos_vars\",nargs=\"*\")  # gt_id and horizon \n",
    "    parser.add_argument('--model_name', '-mn', default=\"climpp\")                                                                                 \n",
    "    parser.add_argument('--target_dates', '-t', default=\"std_test\")\n",
    "    parser.add_argument('--num_years', '-y', default=\"all\",\n",
    "                       help=\"Number of years to use in training (all or integer)\")\n",
    "    parser.add_argument('--margin_in_days', '-m', default=\"None\", \n",
    "                       help=\"Number of month-day combinations on either side of the target combination to include; \"\n",
    "                            \"set to 0 to include only target month-day combo; set to None to include entire year; \"\n",
    "                            \"None by default\")\n",
    "    args = parser.parse_args()\n",
    "    \n",
    "    # Assign variables                                                                                                                                     \n",
    "    gt_id = args.pos_vars[0] # e.g., \"contest_precip\" or \"contest_tmp2m\"                                                                            \n",
    "    horizon = args.pos_vars[1] # e.g., \"12w\", \"34w\", or \"56w\"    \n",
    "    model_name = args.model_name\n",
    "    target_dates = args.target_dates\n",
    "    num_years = args.num_years\n",
    "    if num_years != \"all\":\n",
    "        num_years = int(num_years)\n",
    "    margin_in_days = args.margin_in_days\n",
    "    if margin_in_days == \"None\":\n",
    "        margin_in_days = None\n",
    "    else:\n",
    "        margin_in_days = int(args.margin_in_days)\n",
    "else:\n",
    "    # Otherwise, specify arguments interactively\n",
    "    gt_id = \"global_tmp2m_p1_1.5x1.5\" \n",
    "    horizon = \"34w\"\n",
    "    model_name = \"climpp\" \n",
    "    target_dates = \"s2s\"\n",
    "    num_years = 3\n",
    "    margin_in_days = None\n",
    "\n",
    "\n",
    "#\n",
    "# Process model parameters\n",
    "#\n",
    "# Record output model name and submodel name\n",
    "output_model_name = f\"tuned_{model_name}\"\n",
    "task = f\"{gt_id}_{horizon}\"\n",
    "\n",
    "submodel_name = get_tuner_submodel_name(\n",
    "    output_model_name=output_model_name, num_years=num_years, \n",
    "    margin_in_days=margin_in_days)\n",
    "\n",
    "\n",
    "# Prepare a directory to store tuned model attributes and configuration files\n",
    "src_dir = resource_filename(__name__, os.path.join(\".\"))\n",
    "dst_dir = resource_filename(__name__, os.path.join(\"..\",\"..\",\"models\", output_model_name))\n",
    "if not os.path.exists(dst_dir):\n",
    "    tic()\n",
    "    printf(f'\\nCreating {dst_dir}')\n",
    "    make_directories(dst_dir)\n",
    "    # copy attributes and selected submodel files to output model folder\n",
    "    shutil.copy(os.path.join(src_dir, \"attributes.py\"), os.path.join(dst_dir, \"attributes.py\"))\n",
    "    shutil.copy(os.path.join(src_dir, \"selected_submodel.json\"), os.path.join(dst_dir, \"selected_submodel.json\"))\n",
    "    # update MODEL_NAME in the attribute file\n",
    "    filename = os.path.join(dst_dir, \"attributes.py\")\n",
    "    with open(filename, \"r\") as f:\n",
    "        newText=f.read().replace(\"tuner\", output_model_name)\n",
    "    with open(filename, \"w\") as f:\n",
    "        f.write(newText)\n",
    "    toc()\n",
    "\n",
    "# Create directory for storing forecasts if one does not already exist\n",
    "out_dir = os.path.join(\"models\", output_model_name, \"submodel_forecasts\", \n",
    "                       submodel_name, f\"{gt_id}_{horizon}\")\n",
    "if not os.path.exists(out_dir):\n",
    "    make_directories(out_dir)\n",
    "    \n",
    "\n",
    "if not isnotebook():\n",
    "    # Save output to log file\n",
    "    logger = start_logger(model=output_model_name,submodel=submodel_name,gt_id=gt_id,\n",
    "                          horizon=horizon,target_dates=target_dates)\n",
    "    # Store parameter values in log\n",
    "    params_names = ['gt_id', 'horizon', 'model_name', \n",
    "                    'target_dates', 'num_years', 'margin_in_days']\n",
    "    params_values = [eval(param) for param in params_names]\n",
    "    log_params(params_names, params_values)\n",
    "\n",
    "# Select target dates and restrict to dates with available ground truth data\n",
    "target_date_objs = get_target_dates(target_dates, horizon=horizon)\n",
    "#print(target_date_objs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "printf(f'\\nLoading metrics of {model_name} submodels')\n",
    "if gt_id in [\"global_precip_p1_1.5x1.5\", \"global_precip_p3_1.5x1.5\",\n",
    "             \"global_tmp2m_p1_1.5x1.5\", \"global_tmp2m_p3_1.5x1.5\"]:\n",
    "    # Use s2s_eval dates for S2S gt_id's\n",
    "    tic()\n",
    "    metric_df = load_metric_df(gt_id=gt_id, target_horizon=horizon, model_name=model_name, metric=\"wtd_mse\",\n",
    "                               metric_file_regex=\"*s2s_eval*\", first_year=2017)\n",
    "    toc()    \n",
    "else:\n",
    "    tic()\n",
    "    metric_df = load_metric_df(gt_id=gt_id, target_horizon=horizon, model_name=model_name)\n",
    "    toc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "printf(f\"\\n Loading ground truth\")\n",
    "tic()\n",
    "var = get_measurement_variable(gt_id)\n",
    "gt = data_loaders.get_ground_truth(gt_id).loc[:,[\"start_date\",\"lat\",\"lon\",var]]\n",
    "gt = gt.set_index(['start_date'])\n",
    "gt = gt.dropna(how='any')\n",
    "toc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Generate predictions\n",
    "#\n",
    "# Template for selected submodel forecast file\n",
    "src_file_template = os.path.join(\"models\", model_name, \"submodel_forecasts\", \"{}\", \n",
    "                                 f\"{gt_id}_{horizon}\", f\"{gt_id}_{horizon}\"+\"-{}.h5\")\n",
    "# Auxiliary dataframe used to identify tuning dates\n",
    "X = pd.DataFrame(index=metric_df.index, columns = [\"delta\", \"dividend\", \"remainder\"], \n",
    "                 dtype=np.float64)\n",
    "rmses = pd.Series(index=target_date_objs, dtype=np.float64)\n",
    "for target_date_obj in target_date_objs:\n",
    "    tic()\n",
    "    target_date_str = datetime.strftime(target_date_obj, '%Y%m%d')\n",
    "    # Determine which dates will be used to assess submodels\n",
    "    printf(f\"\\n\\nObtaining tuning dates for target date {target_date_str}\")\n",
    "    tic()\n",
    "    tuning_dates = get_tuning_dates(gt_id, horizon, target_date_obj, \n",
    "                                    num_years, margin_in_days, X)\n",
    "    \n",
    "    #print(tuning_dates)\n",
    "    if not tuning_dates.any():\n",
    "        printf(f\"Warning: No tuning dates have RMSEs for target date {target_date_str}; skipping\")\n",
    "        continue\n",
    "    toc()\n",
    "    printf(f\"Selecting most accurate submodel\")\n",
    "    tic()\n",
    "    # Select most accurate submodel across these dates\n",
    "    model_selected_submodel = metric_df[tuning_dates].mean().idxmin()\n",
    "    # Form forecast by softlinking to selected submodel forecast\n",
    "    src_file = src_file_template.format(model_selected_submodel, target_date_str) \n",
    "    toc()\n",
    "    printf(f\"Selected predictions -- {model_selected_submodel} for target_date {target_date_str}\")\n",
    "    if os.path.isfile(src_file):\n",
    "        tic()\n",
    "        dst_file = os.path.join(out_dir, f\"{gt_id}_{horizon}-{target_date_str}.h5\")\n",
    "        #if target_date_obj > last_train_date:\n",
    "        printf(f\"Saving predictions\")\n",
    "        symlink(src_file, dst_file, use_abs_path=True)\n",
    "        toc()\n",
    "        if target_date_obj in gt.index:\n",
    "            printf(f\"Calculating rmse\")\n",
    "            tic()\n",
    "            preds = pd.read_hdf(src_file)\n",
    "            rmse = np.sqrt(np.square(preds.set_index(['start_date'])[\"pred\"] - gt.loc[target_date_obj,:][var]).mean())\n",
    "            rmses.loc[target_date_obj] = rmse\n",
    "            toc()\n",
    "    else:\n",
    "        printf(f\"Warning: Missing file:\\n{src_file}\")\n",
    "    printf(f\"Total processing time\")\n",
    "    toc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
