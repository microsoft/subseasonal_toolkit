{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debiased ECMWF\n",
    "\n",
    "Standard debiasing of ECMWF ensemble forecasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "from subseasonal_toolkit.utils.notebook_util import isnotebook\n",
    "if isnotebook():\n",
    "    # Autoreload packages that are modified\n",
    "    %load_ext autoreload\n",
    "    %autoreload 2\n",
    "else:\n",
    "    from argparse import ArgumentParser\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "from ttictoc import tic, toc\n",
    "from subseasonal_data.utils import get_measurement_variable\n",
    "from subseasonal_toolkit.utils.general_util import printf\n",
    "from subseasonal_toolkit.utils.experiments_util import (get_first_year, get_start_delta,\n",
    "                                                        get_forecast_delta)\n",
    "from subseasonal_toolkit.utils.models_util import (get_submodel_name, start_logger, log_params, get_forecast_filename,\n",
    "                                                   save_forecasts)\n",
    "from subseasonal_toolkit.utils.eval_util import get_target_dates, mean_rmse_to_score, save_metric\n",
    "from subseasonal_toolkit.models.deb_ecmwf.ecmwf_utils import geometric_median, ssm\n",
    "\n",
    "from subseasonal_data import data_loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Specify model parameters\n",
    "#\n",
    "model_name = \"deb_ecmwf\"\n",
    "if not isnotebook():\n",
    "    # If notebook run as a script, parse command-line arguments\n",
    "    parser = ArgumentParser()\n",
    "    parser.add_argument(\"pos_vars\",nargs=\"*\")  # gt_id and horizon \n",
    "    parser.add_argument('--target_dates', '-t', default=\"std_test\")\n",
    "    parser.add_argument('--train_years', '-y', default=20,\n",
    "                       help=\"Number of years to use in debiasing (integer)\")     \n",
    "    parser.add_argument('--loss', '-l', default=\"mse\", \n",
    "                        help=\"loss function: mse, rmse, skill, or ssm\")\n",
    "    parser.add_argument('--first_lead', '-fl', default=15, \n",
    "                        help=\"first ecmwf lead to average into forecast (0-29)\")\n",
    "    parser.add_argument('--last_lead', '-ll', default=15, \n",
    "                        help=\"last ecmwf lead to average into forecast (0-29)\")\n",
    "    parser.add_argument('--forecast_with', '-fw', default=\"c\", \n",
    "                        help=\"Generate forecast using the control (c), \"\n",
    "                        \"average perturbed (p), single perturbed (p1, ..., p50), \"\n",
    "                        \"or perturbed-control ensemble (p+c) ECMWF forecast.\")\n",
    "    parser.add_argument('--debias_with', '-dw', default=\"c\", \n",
    "                        help=\"Debias using the control (c), average perturbed (p), \"\n",
    "                        \"or perturbed-control ensemble (p+c) ECMWF reforecast.\")      \n",
    "  \n",
    "    args, opt = parser.parse_known_args()\n",
    "    \n",
    "    # Assign variables\n",
    "    gt_id = args.pos_vars[0] # \"contest_precip\" or \"contest_tmp2m\"\n",
    "    horizon = args.pos_vars[1] # \"12w\", \"34w\", or \"56w\"\n",
    "    target_dates = args.target_dates\n",
    "    train_years = int(args.train_years)\n",
    "    loss = args.loss\n",
    "    first_lead = int(args.first_lead)\n",
    "    last_lead = int(args.last_lead)\n",
    "    debias_with = args.debias_with\n",
    "    forecast_with = args.forecast_with \n",
    "else:\n",
    "    # Otherwise, specify arguments interactively \n",
    "    gt_id = \"us_precip_1.5x1.5\" # us_tmp2m_1.5x1.5, must use 1.5x1.5 forecasts for ecmwf\n",
    "    horizon = \"34w\"\n",
    "    target_dates = \"std_ecmwf\"\n",
    "    loss = \"mse\"\n",
    "    train_years = 20\n",
    "    if \"tmp2m\" in gt_id and (horizon == \"34w\"):\n",
    "        first_lead = 15\n",
    "        last_lead = 15\n",
    "    elif \"precip\" in gt_id and (horizon == \"34w\"):\n",
    "        first_lead = 15\n",
    "        last_lead = 15\n",
    "    elif \"tmp2m\" in gt_id and (horizon == \"56w\"):\n",
    "        first_lead = 29\n",
    "        last_lead = 29\n",
    "    elif \"precip\" in gt_id and (horizon == \"56w\"):\n",
    "        first_lead = 29\n",
    "        last_lead = 29\n",
    "    debias_with = \"p+c\"\n",
    "    forecast_with = \"p+c\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "Choose regression parameters and record standard settings\n",
    "of these parameters\n",
    "\"\"\"\n",
    "x_cols = ['zeros']\n",
    "if \"tmp2m\" in gt_id:\n",
    "    base_col = 'ecmwf_tmp2m'\n",
    "elif \"precip\" in gt_id:\n",
    "    base_col = 'ecmwf_precip' \n",
    "group_by_cols = ['lat', 'lon']    \n",
    "\n",
    "\"\"\" \n",
    "Process model parameters\"\"\"\n",
    "\n",
    "# Get list of target date objects\n",
    "target_date_objs = pd.Series(get_target_dates(\n",
    "    date_str=target_dates, horizon=horizon))\n",
    "\n",
    "# Identify measurement variable name\n",
    "measurement_variable = get_measurement_variable(gt_id) # 'tmp2m' or 'precip'\n",
    "\n",
    "# Column names for gt_col, clim_col and anom_col \n",
    "gt_col = measurement_variable\n",
    "clim_col = measurement_variable+\"_clim\"\n",
    "anom_col = get_measurement_variable(gt_id)+\"_anom\" # 'tmp2m_anom' or 'precip_anom'\n",
    "\n",
    "# Store delta between target date and forecast issuance date\n",
    "forecast_delta =  timedelta(days=get_start_delta(horizon, gt_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Don't save forecasts for years earlier than LAST_SAVE_YEAR\n",
    "LAST_SAVE_YEAR = get_first_year(model_name) \n",
    "\n",
    "# Record model and submodel names\n",
    "submodel_name = get_submodel_name(\n",
    "    model_name, train_years=train_years, loss=loss, \n",
    "    first_lead=first_lead, last_lead=last_lead,\n",
    "    forecast_with=forecast_with, debias_with=debias_with)\n",
    "print(submodel_name)\n",
    "\n",
    "if not isnotebook():\n",
    "    # Save output to log file\n",
    "    logger = start_logger(model=model_name,submodel=submodel_name, gt_id=gt_id,\n",
    "                          horizon=horizon, target_dates=target_dates)\n",
    "    # Store parameter values in log                                                                                                                        \n",
    "    params_names = ['gt_id', 'horizon', 'target_dates', 'train_years', 'loss', \n",
    "                    'first_lead', 'last_lead', 'forecast_with', 'debias_with',\n",
    "                    'base_col', 'x_cols', 'group_by_cols']\n",
    "    params_values = [eval(param) for param in params_names]\n",
    "    log_params(params_names, params_values)\n",
    "    \n",
    "# Select estimator based on loss\n",
    "if loss == \"rmse\":\n",
    "    estimator = geometric_median \n",
    "elif loss == \"ssm\":\n",
    "    estimator = ssm\n",
    "else: \n",
    "    estimator = np.mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and process data\n",
    "printf(\"Loading ecmwf data\")\n",
    "# Choose data shift based on horizon and first day to be averaged\n",
    "base_shift = get_forecast_delta(horizon)\n",
    "\n",
    "if gt_id.startswith('us_'):\n",
    "    \"\"\"Load forecast and reforecast data.\"\"\"\n",
    "    cols = [\"iri_ecmwf_\"+gt_id.split(\"_\")[1]+\"-{}.5d_shift{}\".format(col, base_shift) \n",
    "            for col in range(first_lead, last_lead+1)]\n",
    "    # Create list of forecast and reforecast data to load\n",
    "    load_names = []\n",
    "    if forecast_with == \"p+c\":\n",
    "        forecast_prefix = \"ef\"\n",
    "    else:\n",
    "        # Construct forecast name prefix with format cf, pf, pf1, ..., pf50\n",
    "        forecast_prefix = forecast_with[:1]+\"f\"+forecast_with[1:]\n",
    "    load_names.append(forecast_prefix+\"-forecast\")\n",
    "    if debias_with == \"p+c\":\n",
    "        debias_prefix = \"ef\"\n",
    "    else:\n",
    "        # Construct forecast name prefix with format cf, pf\n",
    "        debias_prefix = debias_with[:1]+\"f\"+debias_with[1:]\n",
    "    load_names.append(debias_prefix+\"-reforecast\")\n",
    "    load_data = {}\n",
    "    mask_df = data_loaders.get_us_mask(fname=\"us_1_5_mask.nc\", sync=False)\n",
    "    for l in load_names:\n",
    "        print(\"Loading data.\")\n",
    "        load_data[l] = data_loaders.get_forecast(f\"ecmwf-{measurement_variable}-us1_5-{l}\", \n",
    "                                         mask_df=mask_df,\n",
    "                                         shift=base_shift,\n",
    "                                         sync=False)  \n",
    "        \n",
    "        # Undo-shifting of model_issuance_date so that it matches the start date\n",
    "        # TODO: this is otherwise very hard to do via the shift_df funtion, but it \n",
    "        # would be nice to have a better way of doing this\\\n",
    "        if \"reforecast\" in l:\n",
    "            load_data[l]['model_issuance_date'] = load_data[l][f'model_issuance_date_shift{base_shift}'] \\\n",
    "                + timedelta(days=base_shift)            \n",
    "\n",
    "        printf(\"Averaging leads for forecast and debias data.\")\n",
    "        load_data[l][base_col] = load_data[l][cols].mean(axis=1)\n",
    "\n",
    "        printf('Pivoting dataframe to have one row per start_date')\n",
    "        if \"reforecast\" in l:\n",
    "            load_data[l] = load_data[l][\n",
    "                ['lat','lon','start_date', 'model_issuance_date', base_col]].set_index(\n",
    "                ['lat','lon','start_date', 'model_issuance_date']).unstack(['lat','lon'])            \n",
    "        else:\n",
    "            load_data[l] = load_data[l][['lat','lon','start_date', base_col]].set_index(\n",
    "                ['lat','lon','start_date']).unstack(['lat','lon'])     \n",
    "    \n",
    "else:\n",
    "    raise ValueError(\"ECMWF model only configured for US gt_ids for now.\")            \n",
    "\n",
    "# forecast_prefix in {\"ef\",\"cf\",\"pf\",\"pf1\",...,\"pf50\"}\n",
    "forecast_data = load_data[f\"{forecast_prefix}-forecast\"]\n",
    "# debias_prefix in {\"ef\",\"cf\",\"pf\"}\n",
    "debias_data = load_data[f\"{debias_prefix}-reforecast\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Load and merge ground truth \n",
    "\"\"\"\n",
    "printf('Pivoting ground truth to have one row per start_date')\n",
    "gt = data_loaders.get_ground_truth(gt_id)\\\n",
    "        .loc[:,['lat','lon','start_date', gt_col]]\n",
    "\n",
    "# Need gt for both the debias and the forecast dates\n",
    "gt = gt.loc[gt.start_date.isin(\n",
    "                debias_data.index.get_level_values(\"start_date\") |\n",
    "                forecast_data.index.get_level_values(\"start_date\")),\n",
    "            ['lat','lon','start_date', gt_col]].set_index(\n",
    "            ['lat','lon','start_date']).unstack(['lat','lon'])\n",
    "\n",
    "printf(\"Merging ground truth\")\n",
    "debias_data = debias_data.join(gt, how=\"left\", on=\"start_date\") \n",
    "forecast_data = forecast_data.join(gt, how=\"left\", on=\"start_date\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute debiasing correction\n",
    "printf('Compute debiasing correction (ground-truth - base prediction) by month-day combination')\n",
    "\n",
    "# Compute bias\n",
    "bias = (debias_data[gt_col] - debias_data[base_col])\n",
    "\n",
    "# Initialize bias per start_date dataframe in forecast dir\n",
    "avg_bias = pd.DataFrame(columns=bias.columns, \n",
    "                        index=bias.index.get_level_values(\n",
    "                            'model_issuance_date').unique().sort_values(), \n",
    "                        dtype=np.float64)\n",
    "\n",
    "margin_in_days = 6\n",
    "for (date, df) in bias.groupby(by=\"model_issuance_date\"):\n",
    "    # Get all forecasts within margin of the day/month of the current forecast\n",
    "    last_train_date = date - forecast_delta\n",
    "    debias = bias[\n",
    "        (bias.index.get_level_values(\"start_date\") >= str(date.year - train_years)) &        \n",
    "        (bias.index.get_level_values(\"start_date\") <= last_train_date) &        \n",
    "        (bias.index.get_level_values(\"model_issuance_date\") <= date + timedelta(days=margin_in_days)) &\n",
    "        (bias.index.get_level_values(\"model_issuance_date\") >= date - timedelta(days=margin_in_days))]\n",
    "    \n",
    "    avg_bias.loc[date] = estimator(debias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions for each target date\n",
    "printf('Creating dataframe to store performance')\n",
    "rmses = pd.Series(index=target_date_objs, dtype=np.float64)\n",
    "\n",
    "printf('Forming debiased predictions for target dates')\n",
    "# Form predictions for target dates in data matrix\n",
    "valid_targets = forecast_data.index.intersection(target_date_objs) # intersect with forecast data\n",
    "valid_targets = avg_bias.index.intersection(valid_targets) # intersect with debiasing data\n",
    "\n",
    "preds = forecast_data.loc[valid_targets, base_col] + avg_bias.loc[valid_targets]\n",
    "preds.index.name = \"start_date\"\n",
    "\n",
    "# Ensure precipitation predictions are never less than zero\n",
    "if gt_id.endswith(\"precip\") or gt_id.endswith(\"precip_1.5x1.5\"):\n",
    "    tic()\n",
    "    preds = np.maximum(preds,0.)\n",
    "    toc()\n",
    "\n",
    "# Order valid targets by day of week\n",
    "# valid_targets = valid_targets[valid_targets.weekday.argsort(kind='stable')]\n",
    "for target_date_obj in valid_targets:\n",
    "    # Skip if forecast already produced for this target\n",
    "    target_date_str = datetime.strftime(target_date_obj, '%Y%m%d')\n",
    "    forecast_file = get_forecast_filename(\n",
    "        model=model_name, submodel=submodel_name, \n",
    "        gt_id=gt_id, horizon=horizon, \n",
    "        target_date_str=target_date_str)\n",
    "    if os.path.isfile(forecast_file) and False:\n",
    "        printf(f\"prior forecast exists for target={target_date_obj}\")\n",
    "        pred = pd.read_hdf(forecast_file).set_index(['lat','lon']).pred\n",
    "    else:\n",
    "        printf(f'Processing {model_name} forecast for {target_date_obj}')\n",
    "        tic()\n",
    "        # Get prediction \n",
    "        pred = preds.loc[target_date_obj,:]\n",
    "        # Save prediction to file in standard format\n",
    "        if target_date_obj.year >= LAST_SAVE_YEAR:\n",
    "            save_forecasts(\n",
    "                preds.loc[[target_date_obj],:].unstack().rename(\"pred\").reset_index(),\n",
    "                model=model_name, submodel=submodel_name, \n",
    "                gt_id=gt_id, horizon=horizon, \n",
    "                target_date_str=target_date_str)\n",
    "        toc()\n",
    "    # Evaluate and store error if we have ground truth data\n",
    "    tic()\n",
    "    if target_date_obj in forecast_data.index:\n",
    "        rmse = np.sqrt(np.square(pred - forecast_data.loc[target_date_obj, gt_col]).mean())\n",
    "        rmses.loc[target_date_obj] = rmse\n",
    "        printf(\"-rmse: {}, score: {}\".format(rmse, mean_rmse_to_score(rmse)))\n",
    "        mean_rmse = rmses.mean()\n",
    "        printf(\"-mean rmse: {}, running score: {}\".format(mean_rmse, mean_rmse_to_score(mean_rmse)))\n",
    "    toc()\n",
    "\n",
    "printf(\"Save rmses in standard format\")\n",
    "rmses = rmses.sort_index().reset_index()\n",
    "rmses.columns = ['start_date','rmse']\n",
    "save_metric(rmses, model=model_name, submodel=submodel_name, \n",
    "            gt_id=gt_id, horizon=horizon, target_dates=target_dates, \n",
    "            metric=\"rmse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
